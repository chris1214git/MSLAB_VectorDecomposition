{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16096b03",
   "metadata": {},
   "source": [
    "# MLP baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815ade9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils.eval import retrieval_normalized_dcg_all, retrieval_precision_all, retrieval_precision_all_v2, semantic_precision_all, semantic_precision_all_v2, precision_recall_f1_all\n",
    "from utils.loss import *\n",
    "from utils.data_loader import load_document\n",
    "from utils.toolbox import preprocess_document, get_preprocess_document, get_preprocess_document_embs,\\\n",
    "                          get_preprocess_document_labels, get_preprocess_document_labels_v2, get_word_embs,\\\n",
    "                          get_free_gpu, merge_targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da837f",
   "metadata": {},
   "source": [
    "## Load Data, Label\n",
    "label -> bow, tf-idf, keybert, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06caec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset ='20news'\n",
    "# cross domain\n",
    "dataset2 = None # None\n",
    "model_name = 'average'\n",
    "label_type = 'tf-idf'\n",
    "# 用binary(f1) evaluation或rank evaluation\n",
    "eval_f1 = False\n",
    "criterion = 'BCE'#'ListNet_sigmoid_L1'\n",
    "# 選preprocess config\n",
    "preprocess_config_dir = 'parameters_baseline2'\n",
    "n_gram = 1\n",
    "\n",
    "lr = 1e-3\n",
    "n_epoch = 300\n",
    "valid_epoch = 10\n",
    "h_dim = 300\n",
    "target_normalization = False\n",
    "\n",
    "# 訓練幾次\n",
    "n_time = 1\n",
    "seed = 33\n",
    "if dataset2:\n",
    "    experiment_dir = f'cross_{dataset}_{dataset2}_{model_name}_{label_type}_{criterion}'\n",
    "else:\n",
    "    experiment_dir = f'{dataset}_{model_name}_{label_type}_{criterion}'\n",
    "    \n",
    "save_dir = 'default'\n",
    "\n",
    "config = {}\n",
    "config['experiment_dir'] = experiment_dir\n",
    "config['preprocess_config_dir'] = preprocess_config_dir\n",
    "config['save_dir'] = save_dir\n",
    "config['dataset'] = dataset\n",
    "config['dataset2'] = dataset2\n",
    "config['model_name'] = model_name\n",
    "config['label_type'] = label_type\n",
    "config['eval_f1'] = eval_f1\n",
    "config['n_gram'] = n_gram\n",
    "config['criterion'] = criterion\n",
    "config['n_time'] = n_time\n",
    "config['seed'] = seed\n",
    "\n",
    "config['lr'] = lr\n",
    "config['n_epoch'] = n_epoch\n",
    "config['valid_epoch'] = valid_epoch\n",
    "config['h_dim'] = h_dim\n",
    "config['target_normalization'] = target_normalization\n",
    "        \n",
    "save_dir = os.path.join('experiment', config['experiment_dir'], config['save_dir'])\n",
    "os.makedirs(save_dir, exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ceca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(config, dataset):\n",
    "    preprocess_config_dir = config['preprocess_config_dir']\n",
    "    with open(os.path.join(f'../chris/{preprocess_config_dir}', f'preprocess_config_{dataset}.json'), 'r') as f:\n",
    "        preprocess_config = json.load(f)\n",
    "        \n",
    "    # load preprocess dataset\n",
    "    unpreprocessed_docs, preprocessed_docs = get_preprocess_document(**preprocess_config)\n",
    "    print('doc num', len(preprocessed_docs))\n",
    "\n",
    "    # get document embeddings\n",
    "    doc_embs, doc_model, device = get_preprocess_document_embs(preprocessed_docs, model_name)\n",
    "    print('doc_embs', doc_embs.shape)\n",
    "    \n",
    "    # load labels\n",
    "    labels, vocabularys = get_preprocess_document_labels_v2(preprocessed_docs, preprocess_config, preprocess_config_dir, config['n_gram'])    \n",
    "    # check nonzero numbers\n",
    "    for k in labels:\n",
    "        print(k, np.sum(labels[k]!=0), labels[k].shape)\n",
    "    print(len(vocabularys))\n",
    "    # select label type\n",
    "    targets = labels[config['label_type']].toarray()\n",
    "    vocabularys = vocabularys\n",
    "    \n",
    "    return unpreprocessed_docs ,preprocessed_docs, doc_embs, targets, vocabularys, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c09635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting preprocess documents: 20news\n",
      "min_df: 62 max_df: 1.0 vocabulary_size: None min_doc_word: 15\n",
      "doc num 18589\n",
      "Getting preprocess documents embeddings\n",
      "Using cuda 0 for training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c52cf8c28b42509282eb427298b99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_embs (18589, 300)\n",
      "Getting preprocess documents labels\n",
      "Finding precompute_keyword by preprocess_config {'dataset': '20news', 'min_df': 62, 'max_df': 1.0, 'vocabulary_size': None, 'min_doc_word': 15}\n",
      "tf-idf 1092802 (18589, 4823)\n",
      "bow 1092802 (18589, 4823)\n",
      "keybert 1028492 (18589, 4823)\n",
      "yake 892783 (18589, 4823)\n",
      "4823\n"
     ]
    }
   ],
   "source": [
    "unpreprocessed_docs, preprocessed_docs, doc_embs, targets, vocabularys, device = load_training_data(config, config['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c7cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['dataset2'] is not None:\n",
    "    unpreprocessed_docs2, preprocessed_docs2, doc_embs2, targets2, vocabularys2, device = load_training_data(config, config['dataset2'])\n",
    "    targets, targets2, vocabularys = merge_targets(targets, targets2, vocabularys, vocabularys2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb108fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6cf71bdc764b18b400beff6cd7c7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words:400001\n",
      "Getting [ndarray] word embeddings\n",
      "word_embs (4823, 300)\n"
     ]
    }
   ],
   "source": [
    "word_embs = get_word_embs(vocabularys)\n",
    "print('word_embs', word_embs.shape)\n",
    "word_embs_tensor = torch.FloatTensor(word_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a4563",
   "metadata": {},
   "source": [
    "## MLP Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da651ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNDecoderDataset(Dataset):\n",
    "    def __init__(self, doc_embs, targets):\n",
    "        \n",
    "        assert len(doc_embs) == len(targets)\n",
    "\n",
    "        self.doc_embs = torch.FloatTensor(doc_embs)\n",
    "        self.targets = torch.FloatTensor(targets)        \n",
    "        self.targets_rank = torch.argsort(self.targets, dim=1, descending=True)\n",
    "        self.topk = torch.sum(self.targets > 0, dim=1)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.doc_embs[idx], self.targets[idx], self.targets_rank[idx], self.topk[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.doc_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47717a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(doc_embs, targets, batch_size=100, train_valid_test_ratio=[0.7, 0.1, 0.2],\\\n",
    "                       target_normalize=False, seed=123):\n",
    "    train_size = int(len(doc_embs) * train_valid_test_ratio[0])\n",
    "    valid_size = int(len(doc_embs) * (train_valid_test_ratio[0] + train_valid_test_ratio[1])) - train_size\n",
    "    test_size = len(doc_embs) - train_size - valid_size\n",
    "    \n",
    "    print('Preparing dataloader')\n",
    "    print('train size', train_size)\n",
    "    print('valid size', valid_size)\n",
    "    print('test size', test_size)\n",
    "\n",
    "    if target_normalize:\n",
    "        # normalize target summation of each document to 1 \n",
    "        norm = targets.sum(axis=1).reshape(-1, 1)\n",
    "        targets = (targets / norm)\n",
    "        # normalize target L2 norm of each document to 1\n",
    "        # norm = np.linalg.norm(targets, axis=1).reshape(-1, 1)\n",
    "        # targets = (targets / norm)\n",
    "\n",
    "    # shuffle\n",
    "    randomize = np.arange(len(doc_embs))\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(randomize)\n",
    "    doc_embs = doc_embs[randomize]\n",
    "    targets = targets[randomize]\n",
    "    \n",
    "    # dataloader\n",
    "    train_dataset = DNNDecoderDataset(doc_embs[:train_size], targets[:train_size])\n",
    "    train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "    valid_dataset = DNNDecoderDataset(doc_embs[train_size:train_size+valid_size], targets[train_size:train_size+valid_size])\n",
    "    valid_loader  = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "    test_dataset = DNNDecoderDataset(doc_embs[train_size+valid_size:], targets[train_size+valid_size:])\n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def50778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataloader\n",
      "train size 13012\n",
      "valid size 1859\n",
      "test size 3718\n"
     ]
    }
   ],
   "source": [
    "# prepare dataloader\n",
    "train_loader, valid_loader, test_loader = prepare_dataloader(doc_embs, targets, batch_size=64,\\\n",
    "                                                             train_valid_test_ratio=[0.7, 0.1, 0.2],\\\n",
    "                                                             target_normalize=config['target_normalization'],\\\n",
    "                                                             seed=seed)\n",
    "if config['dataset2'] is not None:\n",
    "    _, _, test_loader = prepare_dataloader(doc_embs2, targets2, batch_size=64,\\\n",
    "                                           train_valid_test_ratio=[0.7, 0.1, 0.2],\\\n",
    "                                           target_normalize=config['target_normalization'],\\\n",
    "                                           seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39e0e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNDecoder(nn.Module):\n",
    "    def __init__(self, doc_emb_dim, num_words, h_dim=300):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(doc_emb_dim, h_dim),\n",
    "            # nn.Dropout(p=0.5),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            # nn.Dropout(p=0.5),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(h_dim, num_words),\n",
    "            # nn.Dropout(p=0.5),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b51e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_DNNDecoder(model, data_loader, config, pred_semantic=False):\n",
    "    results = defaultdict(list)\n",
    "    model.eval()\n",
    "    \n",
    "    # predict all data\n",
    "    for data in data_loader:\n",
    "        doc_embs, target, _, _ = data\n",
    "        \n",
    "        doc_embs = doc_embs.to(device)\n",
    "        target = target.to(device)\n",
    "                \n",
    "        pred = model(doc_embs)\n",
    "        if config['eval_f1']:\n",
    "            # Precision / Recall / F1\n",
    "            p, r, f = precision_recall_f1_all(pred, target)\n",
    "            results['precision'].append(p)\n",
    "            results['recall'].append(r)\n",
    "            results['f1_score'].append(f)\n",
    "        else:\n",
    "            # Precision\n",
    "            precision_scores = retrieval_precision_all(pred, target, k=config[\"valid_topk\"])\n",
    "            for k, v in precision_scores.items():\n",
    "                results['precision@{}'.format(k)].append(v)\n",
    "\n",
    "            # Precision\n",
    "            precision_scores = retrieval_precision_all_v2(pred, target, k=config[\"valid_topk\"])\n",
    "            for k, v in precision_scores.items():\n",
    "                results['precisionv2@{}'.format(k)].append(v)\n",
    "\n",
    "            # NDCG\n",
    "            ndcg_scores = retrieval_normalized_dcg_all(pred, target, k=config[\"valid_topk\"])\n",
    "            for k, v in ndcg_scores.items():\n",
    "                results['ndcg@{}'.format(k)].append(v)\n",
    "            \n",
    "            # Semantic Precision\n",
    "            if pred_semantic:\n",
    "                semantic_precision_scores, word_result = semantic_precision_all(pred, target, word_embs_tensor, vocabularys,\\\n",
    "                                                                                k=config[\"valid_topk\"], th=0.5, display_word_result=False)\n",
    "                for k, v in semantic_precision_scores.items():\n",
    "                    results['semantic_precision@{}'.format(k)].append(v)\n",
    "                    \n",
    "                semantic_precision_scores, word_result = semantic_precision_all_v2(pred, target, word_embs_tensor, vocabularys,\\\n",
    "                                                                                k=config[\"valid_topk\"], th=0.5, display_word_result=False)\n",
    "                for k, v in semantic_precision_scores.items():\n",
    "                    results['semantic_precision_v2@{}'.format(k)].append(v)\n",
    "\n",
    "    for k in results:\n",
    "        results[k] = np.mean(results[k])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47bf3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(train_train_config, criterion, pred, target, target_rank, target_topk):\n",
    "    if train_config[\"criterion\"] == \"MultiLabelMarginLoss\":\n",
    "        assert target_rank.shape[0] == len(target_topk)\n",
    "        for i in range(len(target_topk)):\n",
    "            target_rank[i, target_topk[i]] = -1\n",
    "        loss = criterion(pred, target_rank)\n",
    "    elif train_config[\"criterion\"].startswith(\"MultiLabelMarginLossCustomV\"):\n",
    "        loss = criterion(pred, target_rank, target_topk)\n",
    "    elif train_config[\"criterion\"].startswith(\"MultiLabelMarginLossCustom\"):\n",
    "        loss = criterion(pred, target_rank, train_config[\"loss_topk\"])\n",
    "    else:\n",
    "        loss = criterion(pred, target)\n",
    "        \n",
    "    return loss\n",
    "    \n",
    "def train_decoder(doc_embs, targets, train_config):\n",
    "    model = DNNDecoder(doc_emb_dim=doc_embs.shape[1], num_words=targets.shape[1],\\\n",
    "                       h_dim=train_config[\"h_dim\"]).to(device)\n",
    "    model.train()\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=train_config[\"lr\"], weight_decay=train_config[\"weight_decay\"])\n",
    "    # prepare loss\n",
    "    if train_config[\"criterion\"] == \"MultiLabelMarginLoss\":\n",
    "        criterion = nn.MultiLabelMarginLoss(reduction='mean')\n",
    "    elif train_config[\"criterion\"] == \"BCE\":\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    elif train_config[\"criterion\"].startswith(\"MultiLabelMarginLossCustomV\"):\n",
    "        def criterion(a, b, c): return MultiLabelMarginLossCustomV(\n",
    "            a, b, c, float(train_config[\"criterion\"].split(':')[-1]))\n",
    "    elif train_config[\"criterion\"].startswith(\"MultiLabelMarginLossCustom\"):\n",
    "        def criterion(a, b, c): return MultiLabelMarginLossCustom(\n",
    "            a, b, c, float(train_config[\"criterion\"].split(':')[-1]))\n",
    "    else:\n",
    "        criterion = eval(train_config[\"criterion\"])\n",
    "\n",
    "    results = []\n",
    "    n_epoch = train_config[\"n_epoch\"]\n",
    "    valid_epoch = train_config[\"valid_epoch\"]\n",
    "    valid_verbose = train_config[\"valid_verbose\"]\n",
    "\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        train_loss_his = []\n",
    "        valid_loss_his = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for data in train_loader:\n",
    "            doc_embs, target, target_rank, target_topk = data\n",
    "            doc_embs = doc_embs.to(device)\n",
    "            target = target.to(device)\n",
    "            target_rank = target_rank.to(device)\n",
    "            target_topk = target_topk.to(device)\n",
    "            # loss\n",
    "            pred = model(doc_embs)\n",
    "            loss = calculate_loss(train_config, criterion, pred, target, target_rank, target_topk)\n",
    "            train_loss_his.append(loss.item())\n",
    "\n",
    "            # Model backwarding\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        for data in valid_loader:\n",
    "            doc_embs, target, target_rank, target_topk = data\n",
    "            doc_embs = doc_embs.to(device)\n",
    "            target = target.to(device)\n",
    "            target_rank = target_rank.to(device)\n",
    "            target_topk = target_topk.to(device)\n",
    "\n",
    "            # loss\n",
    "            pred = model(doc_embs)\n",
    "            loss = calculate_loss(train_config, criterion, pred, target, target_rank, target_topk)\n",
    "            valid_loss_his.append(loss.item())\n",
    "\n",
    "        print(\"Epoch\", epoch, np.mean(train_loss_his), np.mean(valid_loss_his))\n",
    "\n",
    "        # show decoder result\n",
    "        if (valid_epoch > 0 and epoch % valid_epoch == 0) or epoch == n_epoch-1:\n",
    "            res = {}\n",
    "            res['epoch'] = epoch\n",
    "\n",
    "            train_res_ndcg = evaluate_DNNDecoder(model, train_loader, train_config, True)\n",
    "            valid_res_ndcg = evaluate_DNNDecoder(model, valid_loader, train_config, True)\n",
    "            test_res_ndcg = evaluate_DNNDecoder(model, test_loader, train_config, True)\n",
    "            \n",
    "            res['train'] = train_res_ndcg\n",
    "            res['valid'] = valid_res_ndcg\n",
    "            res['test'] = test_res_ndcg \n",
    "            results.append(res)\n",
    "\n",
    "            if valid_verbose:\n",
    "                print()\n",
    "                print('train', train_res_ndcg)\n",
    "                print('valid', valid_res_ndcg)\n",
    "                print('test', test_res_ndcg)\n",
    "    return results\n",
    "\n",
    "def train_experiment(n_time):\n",
    "    # train n_time in different seed\n",
    "    results = []\n",
    "    for _ in range(n_time):\n",
    "        result = train_decoder(doc_embs, targets, train_config)\n",
    "        results.append(result)\n",
    "\n",
    "    with open(os.path.join(save_dir, 'result.json'), 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72bc3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"n_time\": config['n_time'],\n",
    "    \"lr\": config['lr'],\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"loss_topk\": 15,\n",
    "    \n",
    "    \"n_epoch\": config['n_epoch'],\n",
    "    \"valid_epoch\": config['valid_epoch'],\n",
    "    \"valid_verbose\": True,\n",
    "    \"valid_topk\": [5, 10, 15],\n",
    "    \n",
    "    \"h_dim\": config['h_dim'],\n",
    "    \"label_type\": config['label_type'],\n",
    "    \"eval_f1\": config['eval_f1'],\n",
    "    \"criterion\": config['criterion']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ca730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bbabe4c671490a92cfe0c82f2f3878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 0.03918401733972132 0.00878793808321158\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.7035968283227846, 'precision@10': 0.5397258045918801, 'precision@15': 0.42988359971958046, 'precisionv2@5': 0.005438112856948054, 'precisionv2@10': 0.014342831108746502, 'precisionv2@15': 0.030004086876835895, 'ndcg@5': 0.10569694722253903, 'ndcg@10': 0.10623866889406652, 'ndcg@15': 0.10661182384572777, 'ndcg@all': 0.3901283904617908, 'semantic_precision@5': 0.7176378676470588, 'semantic_precision@10': 0.5782291666666666, 'semantic_precision@15': 0.5771006944444445, 'semantic_precision_v2@5': 0.009025735294117647, 'semantic_precision_v2@10': 0.031421568627450984, 'semantic_precision_v2@15': 0.10375612745098038})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.7156250178813934, 'precision@10': 0.5446875125169754, 'precision@15': 0.434016223748525, 'precisionv2@5': 0.005104166789290806, 'precisionv2@10': 0.014062500186264515, 'precisionv2@15': 0.030069446377456188, 'ndcg@5': 0.10634179661671321, 'ndcg@10': 0.1065765472749869, 'ndcg@15': 0.10705844958623251, 'ndcg@all': 0.3905334641536077, 'semantic_precision@5': 0.7292708333333331, 'semantic_precision@10': 0.5855555555555555, 'semantic_precision@15': 0.582789351851852, 'semantic_precision_v2@5': 0.008333333333333333, 'semantic_precision_v2@10': 0.030416666666666665, 'semantic_precision_v2@15': 0.10194444444444445})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.7056497365741407, 'precision@10': 0.5412605985746546, 'precision@15': 0.4327742720054368, 'precisionv2@5': 0.0050847458463730445, 'precisionv2@10': 0.013638771375862219, 'precisionv2@15': 0.030467280518200437, 'ndcg@5': 0.1053888038179632, 'ndcg@10': 0.10590512816936283, 'ndcg@15': 0.10629823071471715, 'ndcg@all': 0.38964699082455395, 'semantic_precision@5': 0.7193149717514123, 'semantic_precision@10': 0.5785310734463277, 'semantic_precision@15': 0.5781367702448211, 'semantic_precision_v2@5': 0.007944915254237288, 'semantic_precision_v2@10': 0.030261299435028248, 'semantic_precision_v2@15': 0.10519656308851223})\n",
      "Epoch 1 0.008744771879933336 0.008768669283017515\n",
      "Epoch 2 0.008747283382998669 0.00885820264617602\n",
      "Epoch 3 0.00875354087089791 0.00876882957915465\n",
      "Epoch 4 0.008755505308691486 0.008840366173535586\n",
      "Epoch 5 0.008758183600673196 0.008929766869793335\n",
      "Epoch 6 0.008760348770438749 0.008752730923394363\n",
      "Epoch 7 0.00875914514557842 0.008844832641383011\n",
      "Epoch 8 0.008726873864218885 0.008855135831981897\n",
      "Epoch 9 0.00867412444295398 0.008844437170773744\n",
      "Epoch 10 0.008621246558522769 0.00871217700963219\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.6376072483904222, 'precision@10': 0.5234421018291923, 'precision@15': 0.43517158925533295, 'precisionv2@5': 0.008642769781598711, 'precisionv2@10': 0.018630515019336314, 'precisionv2@15': 0.036859683738108356, 'ndcg@5': 0.11520230974636826, 'ndcg@10': 0.11598949218351468, 'ndcg@15': 0.11667819204283696, 'ndcg@all': 0.40127072424865234, 'semantic_precision@5': 0.6838174019607843, 'semantic_precision@10': 0.6525750612745097, 'semantic_precision@15': 0.5756086601307189, 'semantic_precision_v2@5': 0.021081495098039218, 'semantic_precision_v2@10': 0.07376838235294118, 'semantic_precision_v2@15': 0.11468035130718957})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.6382986267407735, 'precision@10': 0.5217708488305409, 'precision@15': 0.4345254848400752, 'precisionv2@5': 0.008541666871557633, 'precisionv2@10': 0.019687500316649675, 'precisionv2@15': 0.03680555808047454, 'ndcg@5': 0.11646286572019258, 'ndcg@10': 0.1166945698360602, 'ndcg@15': 0.11720092768470446, 'ndcg@all': 0.40178756713867186, 'semantic_precision@5': 0.6878125000000002, 'semantic_precision@10': 0.6538194444444445, 'semantic_precision@15': 0.5751736111111111, 'semantic_precision_v2@5': 0.021145833333333332, 'semantic_precision_v2@10': 0.07734375, 'semantic_precision_v2@15': 0.1164351851851852})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.6350988856816696, 'precision@10': 0.5222545993530144, 'precision@15': 0.437246962118957, 'precisionv2@5': 0.008545197988465682, 'precisionv2@10': 0.019518008944973096, 'precisionv2@15': 0.03875353379901183, 'ndcg@5': 0.11431782275943433, 'ndcg@10': 0.11524813735889176, 'ndcg@15': 0.11674403462369563, 'ndcg@all': 0.4007190107289007, 'semantic_precision@5': 0.6828036723163842, 'semantic_precision@10': 0.6514918785310735, 'semantic_precision@15': 0.5770244821092279, 'semantic_precision_v2@5': 0.022722457627118647, 'semantic_precision_v2@10': 0.07545021186440677, 'semantic_precision_v2@15': 0.11796727871939737})\n",
      "Epoch 11 0.008587752898022825 0.008649502725650867\n",
      "Epoch 12 0.008555192075779332 0.008613647986203432\n",
      "Epoch 13 0.008528040868102335 0.008592555113136769\n",
      "Epoch 14 0.008475506997795082 0.008506662972892324\n",
      "Epoch 15 0.008418433840715271 0.008485036560644706\n",
      "Epoch 16 0.008361459134475273 0.008384956683342656\n",
      "Epoch 17 0.008319583422431321 0.00838477114836375\n",
      "Epoch 18 0.008277127681318306 0.00831767061414818\n",
      "Epoch 19 0.008231925479063363 0.008263768426453074\n",
      "Epoch 20 0.008189899744192028 0.008263515339543422\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.4902665531810592, 'precision@10': 0.45075980895290185, 'precision@15': 0.4017248995163861, 'precisionv2@5': 0.051222427446833425, 'precisionv2@10': 0.06555300357514153, 'precisionv2@15': 0.07944138627499342, 'ndcg@5': 0.17126271545010455, 'ndcg@10': 0.1721063003528352, 'ndcg@15': 0.17237492417003594, 'ndcg@all': 0.44959933120830387, 'semantic_precision@5': 0.6250796568627451, 'semantic_precision@10': 0.5844286151960784, 'semantic_precision@15': 0.536609477124183, 'semantic_precision_v2@5': 0.09509191176470588, 'semantic_precision_v2@10': 0.12783394607843138, 'semantic_precision_v2@15': 0.1568188316993464})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.49131945669651034, 'precision@10': 0.4547222296396891, 'precision@15': 0.40273150404294333, 'precisionv2@5': 0.04479166753590107, 'precisionv2@10': 0.061840278158585234, 'precisionv2@15': 0.0786574125289917, 'ndcg@5': 0.16742209643125533, 'ndcg@10': 0.1684848591685295, 'ndcg@15': 0.16955854048331578, 'ndcg@all': 0.44632383485635124, 'semantic_precision@5': 0.6324999999999998, 'semantic_precision@10': 0.5923437500000001, 'semantic_precision@15': 0.5409953703703703, 'semantic_precision_v2@5': 0.08864583333333333, 'semantic_precision_v2@10': 0.12592013888888892, 'semantic_precision_v2@15': 0.15810185185185185})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.4992937935610949, 'precision@10': 0.4567267020880166, 'precision@15': 0.40526132159313916, 'precisionv2@5': 0.050459040202579256, 'precisionv2@10': 0.06344456317187366, 'precisionv2@15': 0.07818385668225207, 'ndcg@5': 0.17161418017694505, 'ndcg@10': 0.17130398598767943, 'ndcg@15': 0.17163740729881546, 'ndcg@all': 0.4464909111039113, 'semantic_precision@5': 0.6326271186440677, 'semantic_precision@10': 0.5893626412429379, 'semantic_precision@15': 0.5400717984934087, 'semantic_precision_v2@5': 0.094579802259887, 'semantic_precision_v2@10': 0.12647422316384183, 'semantic_precision_v2@15': 0.15663841807909604})\n",
      "Epoch 21 0.008148424233784717 0.008177160425111652\n",
      "Epoch 22 0.008100372127385116 0.008122334101547798\n",
      "Epoch 23 0.00804298488404967 0.00806756604773303\n",
      "Epoch 24 0.007977907586952342 0.00806372418689231\n",
      "Epoch 25 0.007902945839233842 0.007986845060562095\n",
      "Epoch 26 0.007835947922157013 0.007884430528307954\n",
      "Epoch 27 0.007763143437092795 0.007886046062534053\n",
      "Epoch 28 0.007701488061095862 0.007832887566958864\n",
      "Epoch 29 0.007634567715428478 0.007786364356676737\n",
      "Epoch 30 0.007565087937822968 0.007717748855551084\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.601712631536465, 'precision@10': 0.515462628912692, 'precision@15': 0.4598437715687004, 'precisionv2@5': 0.1722334591562257, 'precisionv2@10': 0.17217371693136646, 'precisionv2@15': 0.17759396457204632, 'ndcg@5': 0.3542156088001588, 'ndcg@10': 0.34068819909703496, 'ndcg@15': 0.33240536541915405, 'ndcg@all': 0.5613276111144646, 'semantic_precision@5': 0.7145128676470588, 'semantic_precision@10': 0.6270879289215686, 'semantic_precision@15': 0.5701460375816993, 'semantic_precision_v2@5': 0.22339767156862747, 'semantic_precision_v2@10': 0.23464001225490197, 'semantic_precision_v2@15': 0.2491687091503268})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.5879514038562774, 'precision@10': 0.5069097230831782, 'precision@15': 0.45298613409201305, 'precisionv2@5': 0.1547569473584493, 'precisionv2@10': 0.15644097551703454, 'precisionv2@15': 0.16578704863786697, 'ndcg@5': 0.3335229227940241, 'ndcg@10': 0.3212316632270813, 'ndcg@15': 0.3147396147251129, 'ndcg@all': 0.5457513809204102, 'semantic_precision@5': 0.707847222222222, 'semantic_precision@10': 0.6286284722222224, 'semantic_precision@15': 0.5688657407407408, 'semantic_precision_v2@5': 0.20812500000000003, 'semantic_precision_v2@10': 0.22203125, 'semantic_precision_v2@15': 0.24031249999999998})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.5846045274855727, 'precision@10': 0.4998411051297592, 'precision@15': 0.44647483401379345, 'precisionv2@5': 0.14950565223471593, 'precisionv2@10': 0.1537076300483639, 'precisionv2@15': 0.16165843732276206, 'ndcg@5': 0.3233119277125698, 'ndcg@10': 0.3114211347143529, 'ndcg@15': 0.3046388373536579, 'ndcg@all': 0.5389779311115459, 'semantic_precision@5': 0.7045021186440679, 'semantic_precision@10': 0.6170903954802259, 'semantic_precision@15': 0.5633062617702449, 'semantic_precision_v2@5': 0.20496115819209038, 'semantic_precision_v2@10': 0.22029484463276838, 'semantic_precision_v2@15': 0.23755885122410544})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 0.007495969748489705 0.007659391965717077\n",
      "Epoch 32 0.007424191275027161 0.007674167553583781\n",
      "Epoch 33 0.00736150017702112 0.007550055999308825\n",
      "Epoch 34 0.007299444229597701 0.007530270206431548\n",
      "Epoch 35 0.007233985640364243 0.0074957319224874175\n",
      "Epoch 36 0.007167161739084358 0.0074423435144126415\n",
      "Epoch 37 0.007104630844539725 0.0073941457861413555\n",
      "Epoch 38 0.007044324815711554 0.00738908932544291\n",
      "Epoch 39 0.006978418326516654 0.00731164044700563\n",
      "Epoch 40 0.0069180389628836925 0.007221362181007862\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.7495496416208791, 'precision@10': 0.6404687569421881, 'precision@15': 0.5714512128455966, 'precisionv2@5': 0.32661765309817653, 'precisionv2@10': 0.29732077824426634, 'precisionv2@15': 0.28788502470535393, 'ndcg@5': 0.5749370826810014, 'ndcg@10': 0.5411022683861209, 'ndcg@15': 0.5199167528281025, 'ndcg@all': 0.6857049117485682, 'semantic_precision@5': 0.8153523284313725, 'semantic_precision@10': 0.7182720588235295, 'semantic_precision@15': 0.6537888071895427, 'semantic_precision_v2@5': 0.35996629901960786, 'semantic_precision_v2@10': 0.3418566176470589, 'semantic_precision_v2@15': 0.34251736111111114})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.6928819616635641, 'precision@10': 0.5874479313691457, 'precision@15': 0.5280671457449595, 'precisionv2@5': 0.2643055602908134, 'precisionv2@10': 0.24331597487131754, 'precisionv2@15': 0.24186343749364217, 'ndcg@5': 0.4986302892367045, 'ndcg@10': 0.46896527806917826, 'ndcg@15': 0.45299424131711324, 'ndcg@all': 0.6365917225678762, 'semantic_precision@5': 0.779375, 'semantic_precision@10': 0.6855208333333331, 'semantic_precision@15': 0.6253703703703705, 'semantic_precision_v2@5': 0.3049305555555556, 'semantic_precision_v2@10': 0.29560763888888886, 'semantic_precision_v2@15': 0.3042708333333333})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.6860169637001167, 'precision@10': 0.5865466140084348, 'precision@15': 0.5234228114960557, 'precisionv2@5': 0.263347463082459, 'precisionv2@10': 0.24284075074276681, 'precisionv2@15': 0.23933617265547735, 'ndcg@5': 0.4860202154870761, 'ndcg@10': 0.45958201107332264, 'ndcg@15': 0.442764961113364, 'ndcg@all': 0.6307045766862772, 'semantic_precision@5': 0.7692090395480226, 'semantic_precision@10': 0.6801995056497175, 'semantic_precision@15': 0.6199387947269303, 'semantic_precision_v2@5': 0.30607344632768363, 'semantic_precision_v2@10': 0.2989936440677966, 'semantic_precision_v2@15': 0.30464336158192096})\n",
      "Epoch 41 0.006857311971686489 0.007315401531135042\n",
      "Epoch 42 0.006805532986261681 0.007144754193723202\n",
      "Epoch 43 0.006746297816325929 0.00711594110665222\n",
      "Epoch 44 0.006691061923572538 0.007103685770804683\n",
      "Epoch 45 0.006642215252926975 0.007157818910976251\n",
      "Epoch 46 0.006589368385189742 0.007057942900185784\n",
      "Epoch 47 0.0065457575096219195 0.0070312400503704945\n",
      "Epoch 48 0.0065017398903329 0.007042966720958551\n",
      "Epoch 49 0.006450783333503732 0.006983906372139851\n",
      "Epoch 50 0.006406646425032294 0.006985906402890881\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.855686276274569, 'precision@10': 0.7437178460406322, 'precision@15': 0.6624285514448204, 'precisionv2@5': 0.4530147125615793, 'precisionv2@10': 0.40780484661752103, 'precisionv2@15': 0.3864869485590972, 'ndcg@5': 0.7289187887720033, 'ndcg@10': 0.6873157249361861, 'ndcg@15': 0.6578202273915795, 'ndcg@all': 0.7731734204526041, 'semantic_precision@5': 0.8886979166666666, 'semantic_precision@10': 0.7976087622549021, 'semantic_precision@15': 0.7273948120915033, 'semantic_precision_v2@5': 0.47144301470588235, 'semantic_precision_v2@10': 0.4381341911764706, 'semantic_precision_v2@15': 0.4285140931372549})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.747881950934728, 'precision@10': 0.6356076538562775, 'precision@15': 0.5646296640237173, 'precisionv2@5': 0.3358680635690689, 'precisionv2@10': 0.30744792222976686, 'precisionv2@15': 0.2970139026641846, 'ndcg@5': 0.5889527400334676, 'ndcg@10': 0.5547115484873454, 'ndcg@15': 0.5314013699690501, 'ndcg@all': 0.6875480751196543, 'semantic_precision@5': 0.8175000000000001, 'semantic_precision@10': 0.7217881944444444, 'semantic_precision@15': 0.657337962962963, 'semantic_precision_v2@5': 0.37277777777777776, 'semantic_precision_v2@10': 0.35585069444444445, 'semantic_precision_v2@15': 0.35357638888888887})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.7396716182514772, 'precision@10': 0.6329537559363801, 'precision@15': 0.5646539805299144, 'precisionv2@5': 0.32992585382219086, 'precisionv2@10': 0.3009798764172247, 'precisionv2@15': 0.2936617403717364, 'ndcg@5': 0.5785622228000123, 'ndcg@10': 0.5445760417792757, 'ndcg@15': 0.5231680637699062, 'ndcg@all': 0.6832755470679979, 'semantic_precision@5': 0.8119526836158192, 'semantic_precision@10': 0.7206832627118643, 'semantic_precision@15': 0.6594338512241054, 'semantic_precision_v2@5': 0.3661546610169491, 'semantic_precision_v2@10': 0.3500176553672316, 'semantic_precision_v2@15': 0.3535193032015066})\n",
      "Epoch 51 0.006367745231745728 0.007044152775779367\n",
      "Epoch 52 0.006325747422855713 0.00694319762599965\n",
      "Epoch 53 0.006288762501093979 0.006920688366517424\n",
      "Epoch 54 0.006249233178666555 0.006881275850658616\n",
      "Epoch 55 0.006211551933494561 0.006861882656812668\n",
      "Epoch 56 0.006183391402694671 0.006922531857465704\n",
      "Epoch 57 0.006153272122473401 0.0070073926045248905\n",
      "Epoch 58 0.006115086000029217 0.006889323533202211\n",
      "Epoch 59 0.006090026841882397 0.006902229180559516\n",
      "Epoch 60 0.006055711369103223 0.006897365270803372\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.9193566102607578, 'precision@10': 0.8211213367826798, 'precision@15': 0.7380014731019151, 'precisionv2@5': 0.5300061395939659, 'precisionv2@10': 0.4811887291132235, 'precisionv2@15': 0.45509091326419043, 'ndcg@5': 0.8072251294757805, 'ndcg@10': 0.7673775246914696, 'ndcg@15': 0.7359699907840467, 'ndcg@all': 0.8212929975752737, 'semantic_precision@5': 0.9327297794117646, 'semantic_precision@10': 0.8561841299019608, 'semantic_precision@15': 0.7883169934640523, 'semantic_precision_v2@5': 0.5401868872549019, 'semantic_precision_v2@10': 0.5026118259803922, 'semantic_precision_v2@15': 0.48812806372549017})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.7850000063578287, 'precision@10': 0.6755902886390686, 'precision@15': 0.6024074415365855, 'precisionv2@5': 0.3695833384990692, 'precisionv2@10': 0.33663195272286733, 'precisionv2@15': 0.3273032615582148, 'ndcg@5': 0.6321639398733775, 'ndcg@10': 0.5955765684445699, 'ndcg@15': 0.5723023215929667, 'ndcg@all': 0.7138789633909861, 'semantic_precision@5': 0.8455902777777777, 'semantic_precision@10': 0.7546006944444444, 'semantic_precision@15': 0.6931365740740741, 'semantic_precision_v2@5': 0.4020486111111111, 'semantic_precision_v2@10': 0.38008680555555546, 'semantic_precision_v2@15': 0.38299768518518523})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.7739230293338581, 'precision@10': 0.6700476791899083, 'precision@15': 0.599199652671814, 'precisionv2@5': 0.358492239046905, 'precisionv2@10': 0.3322387054815131, 'precisionv2@15': 0.32123942597437716, 'ndcg@5': 0.6187626658859899, 'ndcg@10': 0.5851617041280714, 'ndcg@15': 0.5618717195624012, 'ndcg@all': 0.7076297634738987, 'semantic_precision@5': 0.8324505649717513, 'semantic_precision@10': 0.7509887005649718, 'semantic_precision@15': 0.6886240583804142, 'semantic_precision_v2@5': 0.3914018361581922, 'semantic_precision_v2@10': 0.3773393361581921, 'semantic_precision_v2@15': 0.3783015536723163})\n",
      "Epoch 61 0.006034472815728947 0.006826620316132903\n",
      "Epoch 62 0.006000495216736168 0.00694085811264813\n",
      "Epoch 63 0.005979339443786326 0.0069798014281938475\n",
      "Epoch 64 0.005944942551044126 0.006824723988150557\n",
      "Epoch 65 0.005922174387081873 0.006930380299066504\n",
      "Epoch 66 0.00589774647389776 0.006890921403343479\n",
      "Epoch 67 0.005871304377055198 0.006774362564707796\n",
      "Epoch 68 0.005850901325032407 0.006795987455795209\n",
      "Epoch 69 0.005824502393165056 0.006779021474843224\n",
      "Epoch 70 0.005804999936919878 0.00688249128870666\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.9543382288778529, 'precision@10': 0.8727313271340202, 'precision@15': 0.7950776602123298, 'precisionv2@5': 0.5828952365646175, 'precisionv2@10': 0.5379473105365155, 'precisionv2@15': 0.5105678357330024, 'ndcg@5': 0.8530314301743227, 'ndcg@10': 0.818516697953729, 'ndcg@15': 0.7882037814341339, 'ndcg@all': 0.8524250966661117, 'semantic_precision@5': 0.9554626225490198, 'semantic_precision@10': 0.8942968749999999, 'semantic_precision@15': 0.8322906454248367, 'semantic_precision_v2@5': 0.5896047794117648, 'semantic_precision_v2@10': 0.5542294730392158, 'semantic_precision_v2@15': 0.5369454656862744})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.7942708472410838, 'precision@10': 0.6932291766007741, 'precision@15': 0.6266782820224762, 'precisionv2@5': 0.38121528128782906, 'precisionv2@10': 0.35131944666306175, 'precisionv2@15': 0.34408566951751707, 'ndcg@5': 0.6480561236540476, 'ndcg@10': 0.6140029470125834, 'ndcg@15': 0.5910037537415822, 'ndcg@all': 0.725799423456192, 'semantic_precision@5': 0.8507986111111111, 'semantic_precision@10': 0.7682465277777777, 'semantic_precision@15': 0.7094560185185187, 'semantic_precision_v2@5': 0.41111111111111115, 'semantic_precision_v2@10': 0.3961458333333334, 'semantic_precision_v2@15': 0.39700231481481485})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.7891243019346463, 'precision@10': 0.6876853957014569, 'precision@15': 0.6172610925415815, 'precisionv2@5': 0.37973164552349153, 'precisionv2@10': 0.3473693566807246, 'precisionv2@15': 0.3361935226593987, 'ndcg@5': 0.6419680078150862, 'ndcg@10': 0.6063313969111038, 'ndcg@15': 0.5820547756502183, 'ndcg@all': 0.7212063134726832, 'semantic_precision@5': 0.8425494350282486, 'semantic_precision@10': 0.7632062146892655, 'semantic_precision@15': 0.7036546610169492, 'semantic_precision_v2@5': 0.4106991525423729, 'semantic_precision_v2@10': 0.3925494350282486, 'semantic_precision_v2@15': 0.3927377589453861})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 0.005783513790982611 0.0068720333278179165\n",
      "Epoch 72 0.005761692740990981 0.006839470146223903\n",
      "Epoch 73 0.005742936260432151 0.006839777032534282\n",
      "Epoch 74 0.005723404218716656 0.006860890441263715\n",
      "Epoch 75 0.005701580835853284 0.006827092279369632\n",
      "Epoch 76 0.005683851521918732 0.006840139115229249\n",
      "Epoch 77 0.005666157999989011 0.006832362944260239\n",
      "Epoch 78 0.005652447794929293 0.0069250843022018675\n",
      "Epoch 79 0.005636152619605555 0.006865883649637302\n",
      "Epoch 80 0.005618214098207068 0.006822077433268229\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.9715778225777196, 'precision@10': 0.904739600478434, 'precision@15': 0.8314757443526212, 'precisionv2@5': 0.6173652147545534, 'precisionv2@10': 0.5773697965869716, 'precisionv2@15': 0.5535600749300975, 'ndcg@5': 0.878033299072116, 'ndcg@10': 0.8499383704335082, 'ndcg@15': 0.8224318746258231, 'ndcg@all': 0.8724753310283025, 'semantic_precision@5': 0.9658731617647058, 'semantic_precision@10': 0.9180116421568628, 'semantic_precision@15': 0.8612387663398692, 'semantic_precision_v2@5': 0.6207169117647059, 'semantic_precision_v2@10': 0.5890839460784314, 'semantic_precision_v2@15': 0.5752471405228757})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.7964236199855804, 'precision@10': 0.6938715398311615, 'precision@15': 0.6234838287035624, 'precisionv2@5': 0.3867708365122477, 'precisionv2@10': 0.361232645312945, 'precisionv2@15': 0.35082177619139354, 'ndcg@5': 0.6564399083455403, 'ndcg@10': 0.6224985559781392, 'ndcg@15': 0.5990098595619202, 'ndcg@all': 0.7310951948165894, 'semantic_precision@5': 0.8514583333333332, 'semantic_precision@10': 0.7680381944444445, 'semantic_precision@15': 0.7103703703703703, 'semantic_precision_v2@5': 0.4166666666666667, 'semantic_precision_v2@10': 0.40338541666666666, 'semantic_precision_v2@15': 0.40362268518518524})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.7931850310099327, 'precision@10': 0.6880826414641688, 'precision@15': 0.6207333207130432, 'precisionv2@5': 0.38910664744296314, 'precisionv2@10': 0.3574152619151746, 'precisionv2@15': 0.34804027666479853, 'ndcg@5': 0.6510353563195568, 'ndcg@10': 0.6159205729678526, 'ndcg@15': 0.5927820316815781, 'ndcg@all': 0.7281595690775726, 'semantic_precision@5': 0.8465218926553671, 'semantic_precision@10': 0.7628707627118646, 'semantic_precision@15': 0.7052554143126177, 'semantic_precision_v2@5': 0.4177612994350282, 'semantic_precision_v2@10': 0.40111228813559313, 'semantic_precision_v2@15': 0.40300141242937854})\n",
      "Epoch 81 0.0056007764069363475 0.006797366496175528\n",
      "Epoch 82 0.005589027427976914 0.006772731896489859\n",
      "Epoch 83 0.005573501319661006 0.006720334469961623\n",
      "Epoch 84 0.005559302165684309 0.006840801953027646\n",
      "Epoch 85 0.005546620663474588 0.006818224769085645\n",
      "Epoch 86 0.0055329517036785975 0.006875834986567497\n",
      "Epoch 87 0.005519838147687123 0.006811265476668874\n",
      "Epoch 88 0.00550396999289446 0.006791368902971347\n",
      "Epoch 89 0.005488391141589804 0.006811537810911735\n",
      "Epoch 90 0.0054793538292869925 0.006828677343825499\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.9804963305884716, 'precision@10': 0.9258103721282062, 'precision@15': 0.856269453962644, 'precisionv2@5': 0.6391942588722005, 'precisionv2@10': 0.6063281329823476, 'precisionv2@15': 0.5831209432845023, 'ndcg@5': 0.8927525617912704, 'ndcg@10': 0.8698359196092568, 'ndcg@15': 0.8441630739207361, 'ndcg@all': 0.8856278155364242, 'semantic_precision@5': 0.9726470588235293, 'semantic_precision@10': 0.9342447916666669, 'semantic_precision@15': 0.8800898692810458, 'semantic_precision_v2@5': 0.6413848039215686, 'semantic_precision_v2@10': 0.6157598039215686, 'semantic_precision_v2@15': 0.6013184232026144})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.7947916825612386, 'precision@10': 0.693993067741394, 'precision@15': 0.625740780433019, 'precisionv2@5': 0.3880208432674408, 'precisionv2@10': 0.3656423653165499, 'precisionv2@15': 0.3555671473344167, 'ndcg@5': 0.6483128090699514, 'ndcg@10': 0.6198788662751515, 'ndcg@15': 0.5975319375594457, 'ndcg@all': 0.7303156753381094, 'semantic_precision@5': 0.8461458333333335, 'semantic_precision@10': 0.7648437499999999, 'semantic_precision@15': 0.7077662037037038, 'semantic_precision_v2@5': 0.41951388888888896, 'semantic_precision_v2@10': 0.4059201388888889, 'semantic_precision_v2@15': 0.4071180555555556})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.7838630029710673, 'precision@10': 0.686025792259281, 'precision@15': 0.6194680131087869, 'precisionv2@5': 0.39352048554662933, 'precisionv2@10': 0.36195268772416195, 'precisionv2@15': 0.35188325885999, 'ndcg@5': 0.6516809827190334, 'ndcg@10': 0.6182777992749618, 'ndcg@15': 0.5953702663971205, 'ndcg@all': 0.7304498462353722, 'semantic_precision@5': 0.8391772598870056, 'semantic_precision@10': 0.7612641242937853, 'semantic_precision@15': 0.7046786723163843, 'semantic_precision_v2@5': 0.4239583333333333, 'semantic_precision_v2@10': 0.4055349576271187, 'semantic_precision_v2@15': 0.40512005649717514})\n",
      "Epoch 91 0.005467666817518572 0.006848925398662687\n",
      "Epoch 92 0.00545516640048328 0.006876680984472235\n",
      "Epoch 93 0.005441615061250096 0.006877530242005984\n",
      "Epoch 94 0.005433599359593263 0.0068629377521574495\n",
      "Epoch 95 0.005419629778913862 0.00683393709671994\n",
      "Epoch 96 0.005411998702067078 0.006833047217999895\n",
      "Epoch 97 0.0053994474161014544 0.006854750852410992\n",
      "Epoch 98 0.005390796570709962 0.006781715480610728\n",
      "Epoch 99 0.005378137794597184 0.006791191020359595\n",
      "Epoch 100 0.005368834564590133 0.0068891909904778\n",
      "\n",
      "train defaultdict(<class 'list'>, {'precision@5': 0.9845986588328492, 'precision@10': 0.9386121525483972, 'precision@15': 0.8748070413575453, 'precisionv2@5': 0.6503033261088764, 'precisionv2@10': 0.6253615264214721, 'precisionv2@15': 0.6078268274957058, 'ndcg@5': 0.8998484082666098, 'ndcg@10': 0.88174580709607, 'ndcg@15': 0.8594711966374341, 'ndcg@all': 0.8947039848449183, 'semantic_precision@5': 0.9748468137254903, 'semantic_precision@10': 0.9436305147058823, 'semantic_precision@15': 0.8955555555555555, 'semantic_precision_v2@5': 0.65171875, 'semantic_precision_v2@10': 0.6334742647058823, 'semantic_precision_v2@15': 0.6246200980392156})\n",
      "valid defaultdict(<class 'list'>, {'precision@5': 0.7858680605888366, 'precision@10': 0.6867014030615489, 'precision@15': 0.6171528061230978, 'precisionv2@5': 0.3950694481531779, 'precisionv2@10': 0.36829861203829445, 'precisionv2@15': 0.35648150046666466, 'ndcg@5': 0.6551770369211832, 'ndcg@10': 0.6248925824960073, 'ndcg@15': 0.6017920056978862, 'ndcg@all': 0.7342077573140462, 'semantic_precision@5': 0.8387847222222222, 'semantic_precision@10': 0.7621006944444447, 'semantic_precision@15': 0.7036342592592596, 'semantic_precision_v2@5': 0.4232986111111111, 'semantic_precision_v2@10': 0.41036458333333337, 'semantic_precision_v2@15': 0.4117013888888889})\n",
      "test defaultdict(<class 'list'>, {'precision@5': 0.7781956347368532, 'precision@10': 0.6779308036222296, 'precision@15': 0.61214102829917, 'precisionv2@5': 0.3911016992593216, 'precisionv2@10': 0.361317095615096, 'precisionv2@15': 0.3526659789731947, 'ndcg@5': 0.6490640933230772, 'ndcg@10': 0.6155911704241219, 'ndcg@15': 0.5932912109261852, 'ndcg@all': 0.7298577165199538, 'semantic_precision@5': 0.832274011299435, 'semantic_precision@10': 0.7561264124293785, 'semantic_precision@15': 0.7009828154425614, 'semantic_precision_v2@5': 0.4196504237288136, 'semantic_precision_v2@10': 0.4054466807909604, 'semantic_precision_v2@15': 0.40823328625235406})\n",
      "Epoch 101 0.005363141469584376 0.0068642748209337395\n",
      "Epoch 102 0.0053508323891197935 0.006900931413595875\n",
      "Epoch 103 0.005346288575845606 0.006786264292895794\n",
      "Epoch 104 0.005332143189769019 0.006904164220516881\n",
      "Epoch 105 0.005322100268220347 0.006834811888014277\n",
      "Epoch 106 0.00531634217922521 0.006881700502708555\n",
      "Epoch 107 0.005305659226781013 0.006878810903678338\n",
      "Epoch 108 0.005295775901507952 0.006960154309247931\n",
      "Epoch 109 0.005288070106568436 0.006879752858852347\n",
      "Epoch 110 0.005282556425834841 0.006885825392479698\n"
     ]
    }
   ],
   "source": [
    "train_experiment(train_config['n_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102dbb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save config, training config\n",
    "with open(os.path.join(save_dir, 'config.json'), 'w') as f:\n",
    "    json.dump(config, f)\n",
    "with open(os.path.join(save_dir, 'train_config.json'), 'w') as f:\n",
    "    json.dump(train_config, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
