{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.eval import retrieval_normalized_dcg_all, retrieval_precision_all\n",
    "from utils.toolbox import same_seeds, show_settings, record_settings, get_preprocess_document, get_preprocess_document_embs, get_preprocess_document_labels, get_word_embs\n",
    "\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'dataset': '20news', 'target': 'tf-idf', 'seed': 123, 'ratio': 0.8, 'preprocess_config_dir': 'parameters_baseline2', 'encoder': 'mpnet'}\n",
    "\n",
    "if config['dataset'] == '20news':\n",
    "    config[\"min_df\"], config['max_df'], config['min_doc_word'] = 62, 1.0, 15\n",
    "elif config['dataset'] == 'agnews':\n",
    "    config[\"min_df\"], config['max_df'], config['min_doc_word'] = 425, 1.0, 15\n",
    "elif config['dataset'] == 'IMDB':\n",
    "    config[\"min_df\"], config['max_df'], config['min_doc_word'] = 166, 1.0, 15\n",
    "elif config['dataset'] == 'wiki':\n",
    "    config[\"min_df\"], config['max_df'], config['min_doc_word'] = 2872, 1.0, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_settings(config)\n",
    "same_seeds(config[\"seed\"])\n",
    "\n",
    "# data preprocessing\n",
    "unpreprocessed_corpus, preprocessed_corpus = get_preprocess_document(**config)\n",
    "\n",
    "# generating document embedding\n",
    "doc_embs, doc_model, device = get_preprocess_document_embs(preprocessed_corpus, config['encoder'])\n",
    "print(\"Get doc embedding done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(preprocessed_corpus)\n",
    "\n",
    "train_size = int(len(preprocessed_corpus) * config['ratio'])\n",
    "\n",
    "_, voc_train = get_preprocess_document_labels(preprocessed_corpus[:train_size])\n",
    "_, voc_test = get_preprocess_document_labels(preprocessed_corpus[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_train = voc_train['tf-idf']\n",
    "voc_test = voc_test['tf-idf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordNotInTrain = [w for w in voc_test if w not in voc_train]\n",
    "print(\"Training voc size:{}\".format(len(voc_train)))\n",
    "print(\"Testing voc size:{}\".format(len(voc_test)))\n",
    "print(\"Word in test but not in train:{}\".format(len(wordNotInTrain)))\n",
    "print(\"Word missing percentage:{}\".format(len(wordNotInTrain) / len(voc_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('ide')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93b01c9f8b462d125e9b7e3dc372d155e3c361353c59ed4b88f184963989061d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
