{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/coffree/miniconda3/envs/ide/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from model import Decoder, Seq2Seq\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils.toolbox import same_seeds, show_settings, get_preprocess_document, \\\n",
    "                            get_preprocess_document_embs, get_free_gpu, get_preprocess_document_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoderDataset(Dataset):\n",
    "    def __init__(self, doc_embs, targets, labels):\n",
    "        \n",
    "        assert len(doc_embs) == len(targets)\n",
    "\n",
    "        self.doc_embs = torch.FloatTensor(doc_embs)\n",
    "        self.targets = torch.LongTensor(targets)      \n",
    "        self.labels = torch.FloatTensor(labels)        # TFIDF\n",
    "        # self.targets_rank = torch.argsort(self.targets, dim=1, descending=True)\n",
    "        # self.topk = torch.sum(self.targets > 0, dim=1)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.doc_embs[idx], self.targets[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.doc_embs)\n",
    "\n",
    "def pad_sequence(sentence, word2idx, sen_len):\n",
    "    # 將每個句子變成一樣的長度\n",
    "    if len(sentence) > sen_len:\n",
    "        sentence = sentence[:sen_len]\n",
    "    else:\n",
    "        pad_len = sen_len - len(sentence)\n",
    "        for _ in range(pad_len):\n",
    "            sentence.append(word2idx[\"<PAD>\"])\n",
    "    assert len(sentence) == sen_len\n",
    "    return sentence\n",
    "\n",
    "def prepare_dataloader(doc_embs, targets, labels, batch_size=100, train_valid_test_ratio=[0.7, 0.1, 0.2]):\n",
    "    train_size = int(len(doc_embs) * train_valid_test_ratio[0])\n",
    "    valid_size = int(len(doc_embs) * (train_valid_test_ratio[0] + train_valid_test_ratio[1])) - train_size\n",
    "    test_size = len(doc_embs) - train_size - valid_size\n",
    "    \n",
    "    print('Preparing dataloader')\n",
    "    print('train size', train_size)\n",
    "    print('valid size', valid_size)\n",
    "    print('test size', test_size)\n",
    "\n",
    "    # shuffle\n",
    "    randomize = np.arange(len(doc_embs))\n",
    "    np.random.shuffle(randomize)\n",
    "    doc_embs = doc_embs[randomize]\n",
    "    targets = targets[randomize]\n",
    "    labels = labels[randomize]\n",
    "    \n",
    "    # dataloader\n",
    "    train_dataset = LSTMDecoderDataset(doc_embs[:train_size], targets[:train_size], labels[:train_size])\n",
    "    train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "    valid_dataset = LSTMDecoderDataset(doc_embs[train_size:train_size+valid_size], targets[train_size:train_size+valid_size], labels[train_size:train_size+valid_size])\n",
    "    valid_loader  = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    test_dataset = LSTMDecoderDataset(doc_embs[train_size+valid_size:], targets[train_size+valid_size:], labels[train_size+valid_size:])\n",
    "    test_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def get_document_labels(texts, max_len=50):\n",
    "    word2idx = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2, \"<UNK>\" : 3}\n",
    "    idx2word = {0 : \"<SOS>\", 1 : \"<EOS\", 2 : \"<PAD>\", 3 : \"<UNK>\"}\n",
    "    # Build dictionary\n",
    "    for text in texts:\n",
    "        for word in text:\n",
    "            if (word2idx.get(word, -1) == -1):\n",
    "                idx2word[len(word2idx)] = word\n",
    "                word2idx[word] = len(word2idx)\n",
    "    \n",
    "    # Build labels\n",
    "    # 把句子裡面的字轉成相對應的 index\n",
    "    sentence_list = []\n",
    "    for i, sen in enumerate(texts):\n",
    "        sentence_idx = [word2idx[\"<SOS>\"]]\n",
    "        for word in sen:\n",
    "            if (word in word2idx.keys()):\n",
    "                sentence_idx.append(word2idx[word])\n",
    "            else:\n",
    "                sentence_idx.append(word2idx[\"<UNK>\"])\n",
    "        # 將每個句子變成一樣的長度\n",
    "        sentence_idx = pad_sequence(sentence_idx, word2idx, max_len)\n",
    "        sentence_idx[-1] = word2idx[\"<EOS>\"]\n",
    "        sentence_list.append(sentence_idx)\n",
    "\n",
    "    labels = torch.LongTensor(sentence_list)\n",
    "    return word2idx, idx2word, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='document decomposition.')\n",
    "# parser.add_argument('--model', type=str, default=\"ZTM\")\n",
    "# parser.add_argument('--dataset', type=str, default=\"20news\")\n",
    "# parser.add_argument('--min_df', type=int, default=1)\n",
    "# parser.add_argument('--max_df', type=float, default=1.0)\n",
    "# parser.add_argument('--max_len', type=int, default=50)\n",
    "# parser.add_argument('--num_epoch', type=int, default=50)\n",
    "# parser.add_argument('--min_doc_word', type=int, default=15)\n",
    "# parser.add_argument('--min_doc_len', type=int, default=15)\n",
    "# parser.add_argument('--encoder', type=str, default='bert')\n",
    "# parser.add_argument('--seed', type=int, default=123)\n",
    "# args = parser.parse_args()\n",
    "# config = vars(args)\n",
    "\n",
    "config = {\n",
    "    \"model\": \"ZTM\",\n",
    "    \"dataset\": \"agnews\",\n",
    "    \"max_len\": 30,\n",
    "    \"num_epoch\": 50,\n",
    "    \"min_doc_len\": 15,\n",
    "    \"encoder\": \"bert\",\n",
    "    \"seed\": 123,\n",
    "    \"topk\": [5, 10, 15],\n",
    "    \"target\": \"tf-idf\"\n",
    "}\n",
    "\n",
    "if config['dataset'] == '20news':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 62, 1.0, 15\n",
    "elif config['dataset'] == 'agnews':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 425, 1.0, 15\n",
    "elif config['dataset'] == 'IMDB':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 166, 1.0, 15\n",
    "elif config['dataset'] == 'wiki':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 2872, 1.0, 15\n",
    "elif config['dataset'] == 'tweet':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 5, 1.0, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Info ---------\n",
      "model: ZTM\n",
      "dataset: 20news\n",
      "max_len: 30\n",
      "num_epoch: 50\n",
      "min_doc_len: 15\n",
      "encoder: bert\n",
      "seed: 123\n",
      "topk: [5, 10, 15]\n",
      "target: tf-idf\n",
      "min_df: 62\n",
      "max_df: 1.0\n",
      "min_doc_word: 15\n",
      "\n",
      "-----------------------\n",
      "Getting preprocess documents: 20news\n",
      "min_df: 62 max_df: 1.0 vocabulary_size: None min_doc_word: 15\n",
      "Getting preprocess documents embeddings\n",
      "Using cuda 0 for training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name /home/coffree/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/coffree/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Batches: 100%|██████████| 372/372 [00:23<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get doc embedding done.\n",
      "doc_emb shape: (18589, 768)\n",
      "voc size: 4833\n",
      "labels size: torch.Size([18589, 30])\n",
      "Preparing dataloader\n",
      "train size 13012\n",
      "valid size 1859\n",
      "test size 3718\n"
     ]
    }
   ],
   "source": [
    "show_settings(config)\n",
    "same_seeds(config[\"seed\"])\n",
    "\n",
    "# data preprocessing\n",
    "unpreprocessed_corpus, preprocessed_corpus = get_preprocess_document(**config)\n",
    "\n",
    "# for testing\n",
    "preprocessed_corpus = preprocessed_corpus\n",
    "\n",
    "texts = [text.split() for text in preprocessed_corpus]\n",
    "\n",
    "word2idx, idx2word, labels = get_document_labels(texts, max_len=config[\"max_len\"])\n",
    "\n",
    "# Create tfidf target\n",
    "vectorizer = TfidfVectorizer()\n",
    "targets = vectorizer.fit_transform(preprocessed_corpus).toarray()\n",
    "tfidf_word2idx = vectorizer.vocabulary_\n",
    "\n",
    "# generating document embedding\n",
    "doc_embs, doc_model, device = get_preprocess_document_embs(preprocessed_corpus, config['encoder'])\n",
    "print(\"Get doc embedding done.\")\n",
    "\n",
    "vocabulary_size = len(word2idx)\n",
    "embedding_size = 512\n",
    "hidden_size = doc_embs.shape[1]\n",
    "num_layer = 1\n",
    "drop_out = 0\n",
    "\n",
    "print(\"doc_emb shape: {}\".format(doc_embs.shape))\n",
    "print(\"voc size: {}\".format(vocabulary_size))\n",
    "print(\"labels size: {}\".format(labels.size()))\n",
    "\n",
    "train_loader, valid_loader, test_loader = prepare_dataloader(doc_embs, labels, targets, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.decoder = decoder\n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, doc_emb, trg, teacher_forcing_ratio = 0.5):\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #doc_emb = [batch size, embedding_dim]\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        # hidden = [n layers, batch size, hid dim]\n",
    "        # cell = [n layers, batch size, hid dim]\n",
    "        hidden = torch.unsqueeze(doc_emb, 0)\n",
    "        cell = torch.unsqueeze(doc_emb, 0)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "    def predict(self, doc_emb, word2idx, idx2word, max_len=50):\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #doc_emb = [batch size, embedding_dim]\n",
    "        trg_len = max_len\n",
    "        batch_size = len(doc_emb)\n",
    "        trg_vocab_size = len(word2idx)\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        prediction = torch.zeros(trg_len, batch_size)\n",
    "        predict_voc = torch.zeros(batch_size, len(tfidf_word2idx))\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        # hidden = [n layers, batch size, hid dim]\n",
    "        # cell = [n layers, batch size, hid dim]\n",
    "        hidden = torch.unsqueeze(doc_emb, 0)\n",
    "        cell = torch.unsqueeze(doc_emb, 0)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = torch.LongTensor([word2idx[\"<SOS>\"]] * len(doc_emb)).to(self.device)\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            input = output.argmax(1)\n",
    "\n",
    "            prediction[t] = input\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                if (input[b] != word2idx[\"<SOS>\"] and input[b] != word2idx[\"<PAD>\"]\n",
    "                     and input[b] != word2idx[\"<EOS>\"] and input[b] != word2idx[\"<UNK>\"]):\n",
    "                    input_idx = int(input[b])\n",
    "                    predict_label = tfidf_word2idx.get(idx2word[input_idx], -1)\n",
    "                    if (predict_label != -1):\n",
    "                        predict_voc[b][predict_label] += 1\n",
    "\n",
    "        return prediction.transpose(0, 1), predict_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need decoder part\n",
    "dec = Decoder(vocabulary_size, embedding_size, hidden_size, num_layer, drop_out)\n",
    "model = Seq2Seq(dec, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"<PAD>\"])\n",
    "\n",
    "CLIP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "        doc_emb, trg, _ = batch\n",
    "        doc_emb = doc_emb.to(device)\n",
    "        trg = torch.transpose(trg, 0, 1).to(device)\n",
    "        # doc_emb = [batch_size, emb_dim]\n",
    "        # trg = [trg len, batch size]\n",
    "        # output = [trg len, batch size, output dim]\n",
    "        output = model(doc_emb, trg)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # print(trg.size())\n",
    "        # print(output.size())\n",
    "\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "\n",
    "        # trg = [(trg len - 1) * batch size]\n",
    "        # output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/50, train_loss:2.988927815997337\n",
      "Epoch:20/50, train_loss:1.3029007848709162\n",
      "Epoch:30/50, train_loss:0.3408559844154105\n",
      "Epoch:40/50, train_loss:0.1577367298579626\n",
      "Epoch:50/50, train_loss:0.03332847275105316\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config[\"num_epoch\"]):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    if ((epoch + 1) % 10 == 0): \n",
    "        print(\"Epoch:{}/{}, train_loss:{}\".format(epoch+1, config[\"num_epoch\"], train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docemb = torch.FloatTensor(doc_embs[:2]).to(device)\n",
    "prediction, predict_voc = model.predict(docemb, word2idx, idx2word, config[\"max_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 30])\n",
      "<SOS> berkeley edu cubs article organization university california berkeley lines posting host berkeley pilot net writes era run year cubs think pitcher season helped lead era rotation cubs era <EOS "
     ]
    }
   ],
   "source": [
    "print(prediction.shape)\n",
    "for token in prediction[0]:\n",
    "    idx = int(token)\n",
    "    print(idx2word[idx], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4823])\n",
      "4833\n",
      "4823\n"
     ]
    }
   ],
   "source": [
    "print(predict_voc.size())\n",
    "print(len(word2idx))\n",
    "print(len(tfidf_word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from utils.eval import retrieval_normalized_dcg_all, retrieval_precision_all, retrieval_precision_all_v2\n",
    "\n",
    "def evaluate_Decoder(model, data_loader, config):\n",
    "    results = defaultdict(list)\n",
    "    model.eval()\n",
    "    \n",
    "    # predict all data\n",
    "    for data in data_loader:\n",
    "        doc_embs, _, target = data\n",
    "        \n",
    "        doc_embs = doc_embs.to(device)\n",
    "        target = target.to(device)\n",
    "        _, pred = model.predict(doc_embs, word2idx, idx2word)\n",
    "        pred = pred.to(device)\n",
    "\n",
    "        # Precision\n",
    "        precision_scores = retrieval_precision_all(pred, target, k=config[\"topk\"])\n",
    "        for k, v in precision_scores.items():\n",
    "            results['precision@{}'.format(k)].append(v)\n",
    "\n",
    "        # Precision\n",
    "        precision_scores = retrieval_precision_all_v2(pred, target, k=config[\"topk\"])\n",
    "        for k, v in precision_scores.items():\n",
    "            results['precisionv2@{}'.format(k)].append(v)\n",
    "\n",
    "        # NDCG\n",
    "        ndcg_scores = retrieval_normalized_dcg_all(pred, target, k=config[\"topk\"])\n",
    "        for k, v in ndcg_scores.items():\n",
    "            results['ndcg@{}'.format(k)].append(v)\n",
    "\n",
    "    for k in results:\n",
    "        results[k] = np.mean(results[k])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@5:0.9749\n",
      "precision@10:0.9693\n",
      "precision@15:0.9692\n",
      "precisionv2@5:0.3955\n",
      "precisionv2@10:0.3889\n",
      "precisionv2@15:0.4272\n",
      "ndcg@5:0.6484\n",
      "ndcg@10:0.6548\n",
      "ndcg@15:0.6639\n",
      "ndcg@all:0.7293\n"
     ]
    }
   ],
   "source": [
    "res = evaluate_Decoder(model, test_loader, config)\n",
    "for key, val in res.items():\n",
    "    print(f\"{key}:{val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
