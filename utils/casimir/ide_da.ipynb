{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e84b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from load_pretrain_label import load_preprocess_document_labels\n",
    "#from model.ide_ae_decoder import IDEDataset, IDEAEDecoder\n",
    "from utils.toolbox import same_seeds, show_settings, record_settings, get_preprocess_document, get_preprocess_document_embs, get_preprocess_document_labels, get_word_embs, merge_targets\n",
    "from utils.eval import retrieval_normalized_dcg_all, retrieval_precision_all, semantic_precision_all, retrieval_precision_all_v2, semantic_precision_all_v2\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "torch.set_num_threads(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4220e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import encode\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup, BertTokenizer, BertForMaskedLM, RobertaTokenizer, RobertaForMaskedLM, AlbertTokenizer, AlbertForMaskedLM\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "from utils.loss import MythNet, ContrastiveLoss\n",
    "from utils.eval import retrieval_normalized_dcg_all, retrieval_precision_all, semantic_precision_all, retrieval_precision_all_v2, semantic_precision_all_v2\n",
    "from utils.toolbox import get_free_gpu, record_settings\n",
    "from model.inference_network import ContextualInferenceNetwork\n",
    "\n",
    "class IDEDataset(Dataset):\n",
    "    def __init__(self, docs, corpus, emb, target, real):\n",
    "        \n",
    "        assert len(emb) == len(target)\n",
    "        self.docs = docs\n",
    "        self.corpus = corpus\n",
    "        self.emb = torch.FloatTensor(emb)\n",
    "        self.target = torch.FloatTensor(target)\n",
    "        self.real = torch.LongTensor(real)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.docs[idx], self.corpus[idx], self.emb[idx], self.target[idx], self.real[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.emb)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertForMaskedLM.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "    def forward(self, documents):\n",
    "        return self.get_docvec(documents)\n",
    "\n",
    "    def get_docvec(self, documents):\n",
    "        inputs = self.tokenizer(documents, return_tensors='pt', padding=True,\n",
    "                                truncation=True, max_length=128).to(self.device)\n",
    "        embedding = self.model.bert(**inputs).last_hidden_state[:, 0, :]\n",
    "        return embedding\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim=768, output_dim=100, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim*4),\n",
    "            nn.BatchNorm1d(input_dim*4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_dim*4, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, embs):\n",
    "        recons = self.decoder(embs)\n",
    "        return recons\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, output_dim=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.logit = nn.Linear(input_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, embs):\n",
    "        logits = self.logit(embs)\n",
    "        probs = self.softmax(logits)\n",
    "        return logits, probs\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, hidden_dim=1024):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, 1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim*2, 1, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, feature_dim),\n",
    "        )\n",
    "        self.fc_q = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.fc_k = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.attention = nn.MultiheadAttention(input_dim, 8)\n",
    "\n",
    "    def forward(self, embs, reals):\n",
    "        # 1D Convolution\n",
    "        conv_embs = self.cnn(embs.unsqueeze(dim=-1))\n",
    "        feature = self.fc(conv_embs)\n",
    "        feature = reals * embs + (1 - reals) * feature#.unsqueeze(dim=-1)\n",
    "\n",
    "        # attention block\n",
    "        # q = self.fc_q(embs)\n",
    "        # k = self.fc_k(q)\n",
    "        # feature, _ = self.attention(q, k, embs)\n",
    "\n",
    "        return feature\n",
    "\n",
    "class IDEDADecoder:\n",
    "    def __init__(self, config, label_set, unlabel_set, valid_set, vocab = None, id2token=None, device=None, contextual_dim=768, encoded_dim=768, noise_dim=100, word_embeddings=None, dropout=0.2, momentum=0.99, num_data_loader_workers=mp.cpu_count(), loss_weights=None, eps=1e-8):\n",
    "        self.config = config\n",
    "        self.label_set = label_set\n",
    "        self.unlabel_set = unlabel_set\n",
    "        self.valid_set = valid_set\n",
    "        self.merge_set = None\n",
    "        self.vocab = vocab\n",
    "        self.id2token = id2token\n",
    "        self.device = device\n",
    "        self.contextual_dim = contextual_dim\n",
    "        self.encoded_dim = encoded_dim\n",
    "        self.noise_dim = noise_dim\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.dropout = dropout\n",
    "        self.momentum = momentum\n",
    "        self.num_data_loader_workers = num_data_loader_workers\n",
    "        self.loss_weights = loss_weights\n",
    "        self.eps = eps\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "        self.mse_loss = torch.nn.MSELoss()\n",
    "        self.kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "        # model\n",
    "        self.encoder = Encoder(device)\n",
    "        self.decoder = Decoder(input_dim=contextual_dim, output_dim=len(vocab))\n",
    "        self.classifier = Classifier(input_dim=encoded_dim, output_dim=2)\n",
    "        self.extractor = FeatureExtractor(input_dim=contextual_dim, feature_dim=encoded_dim)\n",
    "        \n",
    "        # optimizer\n",
    "        if config['optim'] == 'AdamW':\n",
    "            self.en_optimizer = AdamW(self.encoder.parameters(), lr=config['lr'], eps=eps)\n",
    "            self.de_optimizer = AdamW(self.decoder.parameters(), lr=config['lr'], eps=eps)\n",
    "            self.cls_optimizer = AdamW(self.classifier.parameters(), lr=config['lr'], eps=eps)\n",
    "            self.ex_optimizer = AdamW(self.extractor.parameters(), lr=config['lr'], eps=eps)\n",
    "        else:\n",
    "            self.en_optimizer = torch.optim.Adam(self.encoder.parameters(), lr=config['lr'], betas=(self.momentum, 0.99), weight_decay=config['weight_decay'])\n",
    "            self.de_optimizer = torch.optim.Adam(self.decoder.parameters(), lr=config['lr'], betas=(self.momentum, 0.99), weight_decay=config['weight_decay'])\n",
    "            self.cls_optimizer = torch.optim.Adam(self.classifier.parameters(), lr=config['lr'], betas=(self.momentum, 0.99), weight_decay=config['weight_decay'])\n",
    "            self.ex_optimizer = torch.optim.Adam(self.extractor.parameters(), lr=config['lr'], betas=(self.momentum, 0.99), weight_decay=config['weight_decay'])\n",
    "                   \n",
    "        # scheduler\n",
    "        if config['scheduler']:\n",
    "            num_en_training_steps = int(len(label_set) / config['batch_size'] * config['en_epochs'])   \n",
    "            num_de_training_steps = int((len(label_set) + len(unlabel_set)) / config['batch_size'] * config['de_epochs'])\n",
    "            num_en_warmup_steps = int(num_en_training_steps * config['warmup_proportion'])\n",
    "            num_de_warmup_steps = int(num_de_training_steps * config['warmup_proportion'])    \n",
    "            if config['warmup'] == 'linear':\n",
    "                self.en_scheduler = get_linear_schedule_with_warmup(self.en_optimizer, num_warmup_steps=num_en_warmup_steps, num_training_steps=num_en_training_steps)\n",
    "                self.de_scheduler = get_linear_schedule_with_warmup(self.de_optimizer, num_warmup_steps=num_de_warmup_steps, num_training_steps=num_de_training_steps)\n",
    "                self.cls_scheduler = get_linear_schedule_with_warmup(self.cls_optimizer, num_warmup_steps=num_de_warmup_steps, num_training_steps=num_de_training_steps)\n",
    "                self.ex_scheduler = get_linear_schedule_with_warmup(self.ex_optimizer, num_warmup_steps=num_de_warmup_steps, num_training_steps=num_de_training_steps)\n",
    "            else:\n",
    "                self.en_scheduler = get_constant_schedule_with_warmup(self.en_optimizer, num_warmup_steps=num_en_warmup_steps)\n",
    "                self.de_scheduler = get_constant_schedule_with_warmup(self.de_optimizer, num_warmup_steps=num_de_warmup_steps)\n",
    "                self.cls_scheduler = get_constant_schedule_with_warmup(self.cls_optimizer, num_warmup_steps=num_de_warmup_steps)\n",
    "                self.ex_scheduler = get_constant_schedule_with_warmup(self.ex_optimizer, num_warmup_steps=num_de_warmup_steps)\n",
    "                \n",
    "    def en_training(self, epoch, loader):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch + 1, self.config['en_epochs']))\n",
    "        print('Encoder Training...')\n",
    "        \n",
    "        en_train_loss = 0\n",
    "        en_train_dis = 0\n",
    "        en_train_cos = 0\n",
    "        \n",
    "        self.encoder.train()\n",
    "\n",
    "        for batch, (docs, corpus, embs, labels, reals) in enumerate(loader):\n",
    "            real_embs = embs.to(self.device)\n",
    "            \n",
    "            real_embs_t = real_embs\n",
    "            \n",
    "            # fake label from BERT            \n",
    "            fake_embs = self.encoder(corpus).to(self.device)\n",
    "\n",
    "            # Encoder's LOSS\n",
    "            # e_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + self.eps))\n",
    "            # e_cos = torch.nn.functional.cosine_similarity(torch.mean(real_embs_t, dim=0), torch.mean(fake_embs, dim=0), dim=0)\n",
    "            e_cos = torch.mean(torch.nn.functional.cosine_similarity(real_embs_t, fake_embs))\n",
    "            # e_feat_emb = torch.mean(torch.pow(torch.mean(real_embs_t, dim=0) - torch.mean(fake_embs, dim=0), 2))\n",
    "            # e_feat_emb =  ContrastiveLoss(real_embs_t, fake_embs, torch.eye(real_embs_t.shape[0], requires_grad=True).to(self.device))\n",
    "            e_feat_emb = torch.mean(torch.mean(torch.cdist(fake_embs, real_embs_t, p=2), dim=0), dim=0).squeeze()\n",
    "            # e_feat_emb = self.kl_loss(fake_embs, real_embs_t)\n",
    "            # e_feat_emb = self.mse_loss(fake_embs, real_embs_t)\n",
    "            # en_loss = e_feat_emb + (1 - e_cos)\n",
    "            en_loss = e_feat_emb + embs.shape[0] * (1 - e_cos)\n",
    "            \n",
    "\n",
    "            self.en_optimizer.zero_grad()\n",
    "            en_loss.backward()\n",
    "            self.en_optimizer.step()\n",
    "            if self.config['scheduler']:\n",
    "                self.en_scheduler.step()\n",
    "\n",
    "            en_train_loss += en_loss.item()\n",
    "            en_train_dis += e_feat_emb\n",
    "            en_train_cos += e_cos\n",
    "\n",
    "        avg_en_train_loss = en_train_loss / len(loader)        \n",
    "        avg_en_train_dis = en_train_dis / len(loader) \n",
    "        avg_en_train_cos = en_train_cos / len(loader) \n",
    "\n",
    "        return avg_en_train_loss, avg_en_train_dis, avg_en_train_cos\n",
    "\n",
    "    def en_validation(self, loader):\n",
    "        \n",
    "        en_val_loss = 0\n",
    "        en_val_dis = 0\n",
    "        en_val_cos = 0\n",
    "        \n",
    "        self.encoder.eval()\n",
    "        # self.classifier.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch, (docs, corpus, embs, labels, reals) in enumerate(loader):\n",
    "                embs = embs.to(self.device)\n",
    "                real_embs_t = embs\n",
    "                \n",
    "                fake_embs = self.encoder(corpus).to(self.device)\n",
    "\n",
    "                # e_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + self.eps))\n",
    "                # e_cos = torch.nn.functional.cosine_similarity(torch.mean(real_embs_t, dim=0), torch.mean(fake_embs, dim=0), dim=0)\n",
    "                e_cos = torch.mean(torch.nn.functional.cosine_similarity(real_embs_t, fake_embs))\n",
    "                # e_feat_emb = torch.mean(torch.pow(torch.mean(real_embs_t, dim=0) - torch.mean(fake_embs, dim=0), 2))\n",
    "                # e_feat_emb =  ContrastiveLoss(real_embs_t, fake_embs, torch.eye(real_embs_t.shape[0], requires_grad=True).to(self.device))\n",
    "                e_feat_emb = torch.mean(torch.mean(torch.cdist(fake_embs, real_embs_t, p=2), dim=0), dim=0).squeeze()\n",
    "                # e_feat_emb = self.kl_loss(fake_embs, real_embs_t)\n",
    "                # e_feat_emb = self.mse_loss(fake_embs, real_embs_t)\n",
    "                # en_loss = e_feat_emb + (1 - e_cos)\n",
    "                en_loss = e_feat_emb + embs.shape[0] * (1 - e_cos)\n",
    "                \n",
    "                en_val_loss += en_loss\n",
    "                en_val_dis += e_feat_emb\n",
    "                en_val_cos += e_cos\n",
    "               \n",
    "            avg_en_val_loss = en_val_loss / len(loader)\n",
    "            avg_en_val_dis = en_val_dis / len(loader)\n",
    "            avg_en_val_cos = en_val_cos / len(loader)\n",
    "        \n",
    "        return avg_en_val_loss, avg_en_val_dis, avg_en_val_cos\n",
    "        \n",
    "    def generate_fake_data(self, loader):\n",
    "        self.encoder.eval()\n",
    "        doc_list = []\n",
    "        corpus_list = []\n",
    "        emb_list = []\n",
    "        label_list = []\n",
    "\n",
    "        for batch, (doc, corpus, embs, labels, reals) in enumerate(loader):\n",
    "            fake_embs = self.encoder(corpus).detach().cpu()\n",
    "            for raw_doc, pro_doc, emb, label in zip(doc, corpus, fake_embs, labels):\n",
    "                doc_list.append(raw_doc)\n",
    "                corpus_list.append(pro_doc)\n",
    "                emb_list.append(emb.numpy())\n",
    "                label_list.append(label.numpy())\n",
    "\n",
    "        return IDEDataset(doc_list, corpus_list, np.array(emb_list), np.array(label_list), np.zeros((len(emb_list), 1)))\n",
    "\n",
    "    def en_fit(self):\n",
    "        self.encoder.to(self.device)\n",
    "\n",
    "        label_loader = DataLoader(self.label_set, batch_size=self.config['batch_size'], shuffle=True, num_workers=self.num_data_loader_workers)\n",
    "        unlabel_loader = DataLoader(self.unlabel_set, batch_size=self.config['batch_size'], shuffle=True, num_workers=self.num_data_loader_workers)\n",
    "        valid_loader = DataLoader(self.valid_set, batch_size=self.config['batch_size'], shuffle=False, num_workers=self.num_data_loader_workers)\n",
    "\n",
    "        for epoch in range(self.config['en_epochs']):\n",
    "            en_train_loss, en_train_dis, en_train_cos = self.en_training(epoch, label_loader)\n",
    "            \n",
    "            en_val_loss, en_val_dis, en_val_cos = self.en_validation(unlabel_loader)\n",
    "            \n",
    "            print('---------------------------------------')\n",
    "            print(\"Training: \")\n",
    "            print(\" [Encoder] Average training loss: {0:.3f}\".format(en_train_loss))\n",
    "            print(\" [Encoder] Average training distance: {0:.3f}\".format(en_train_dis))\n",
    "            print(\" [Encoder] Average training cosine similarity: {0:.3f}\".format(en_train_cos))\n",
    "            print(\"Validation:\")\n",
    "            print(\" [Encoder] Average validation loss: {0:.3f}\".format(en_val_loss))\n",
    "            print(\" [Encoder] Average validation dis: {0:.3f}\".format(en_val_dis))\n",
    "            print(\" [Encoder] Average validation cosine similarity: {0:.3f}\".format(en_val_cos))\n",
    "\n",
    "        self.merge_set = torch.utils.data.ConcatDataset([self.generate_fake_data(unlabel_loader), self.label_set])\n",
    "\n",
    "    def cls_training(self, epoch, loader):        \n",
    "        cls_train_loss = 0\n",
    "        \n",
    "        self.classifier.train()\n",
    "        self.decoder.eval()\n",
    "        self.extractor.eval()\n",
    "\n",
    "        for batch, (docs, corpus, embs, labels, reals) in enumerate(loader):\n",
    "            embs, reals = embs.to(self.device), reals.to(self.device)   \n",
    "\n",
    "            # Extract features\n",
    "            features = self.extractor(embs, reals)\n",
    "            # features = embs\n",
    "            \n",
    "            # Classifier discrimiate features\n",
    "            logits, probs = self.classifier(features)\n",
    "            cls_loss = self.cross_entropy(probs, torch.flatten(reals))\n",
    "            \n",
    "            self.cls_optimizer.zero_grad()\n",
    "            \n",
    "            cls_loss.backward()\n",
    "            \n",
    "            self.cls_optimizer.step()\n",
    "            if self.config['scheduler']:\n",
    "                self.cls_scheduler.step()\n",
    "\n",
    "            cls_train_loss += cls_loss.item()\n",
    "  \n",
    "        avg_cls_train_loss = cls_train_loss / len(loader)    \n",
    "\n",
    "        return avg_cls_train_loss\n",
    "\n",
    "    def de_training(self, epoch, loader):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch + 1, self.config['de_epochs']))\n",
    "        print('Decoder Training...')\n",
    "        \n",
    "        de_train_loss = 0\n",
    "        cls_train_loss = 0\n",
    "\n",
    "        de_loss_weight = 1\n",
    "        cls_loss_weight = 10\n",
    "        \n",
    "        self.classifier.eval()\n",
    "        self.decoder.train()\n",
    "        self.extractor.train()\n",
    "\n",
    "        for batch, (docs, corpus, embs, labels, reals) in enumerate(loader):\n",
    "            embs, labels, reals = embs.to(self.device), labels.to(self.device), reals.to(self.device)   \n",
    "\n",
    "            # Extract features\n",
    "            features = self.extractor(embs, reals)\n",
    "            # features = embs\n",
    "            \n",
    "            # Classifier discrimiate features\n",
    "            logits, probs = self.classifier(features)\n",
    "            # cls_loss = self.cross_entropy(probs, torch.ones([embs.shape[0]], dtype=torch.long).to(self.device))\n",
    "            cls_loss = self.cross_entropy(probs, torch.flatten(1 - reals))\n",
    "            # cls_loss = torch.reciprocal(self.cross_entropy(probs, torch.flatten(reals)) + self.eps)\n",
    "\n",
    "            # Decoder reconstruct embs\n",
    "            recons = self.decoder(features)\n",
    "            \n",
    "            # ListNet Loss\n",
    "            de_loss = de_loss_weight * MythNet(recons, labels) + cls_loss_weight * cls_loss\n",
    "            \n",
    "            self.de_optimizer.zero_grad()\n",
    "            self.ex_optimizer.zero_grad()\n",
    "            \n",
    "            de_loss.backward()\n",
    "            \n",
    "            self.de_optimizer.step()\n",
    "            self.ex_optimizer.step()\n",
    "\n",
    "            if self.config['scheduler']:\n",
    "                self.de_scheduler.step()\n",
    "                self.ex_scheduler.step()\n",
    "\n",
    "            de_train_loss += de_loss.item()\n",
    "\n",
    "        avg_de_train_loss = de_train_loss / len(loader)      \n",
    "\n",
    "        return avg_de_train_loss\n",
    "    \n",
    "    def de_validation(self, loader):\n",
    "        de_val_loss = 0\n",
    "        cls_val_loss = 0\n",
    "\n",
    "        de_loss_weight = 1\n",
    "        cls_loss_weight = 10\n",
    "        \n",
    "        self.classifier.eval()\n",
    "        self.decoder.eval()\n",
    "        self.extractor.eval()\n",
    "        \n",
    "        results = defaultdict(list)\n",
    "        with torch.no_grad():\n",
    "            for batch, (docs, corpus, embs, labels, reals) in enumerate(loader):\n",
    "                embs, labels, reals = embs.to(self.device), labels.to(self.device), reals.to(self.device)\n",
    "                \n",
    "                # Extract features\n",
    "                features = self.extractor(embs, reals)\n",
    "                # features = embs\n",
    "\n",
    "                # Clssifier\n",
    "                logits, probs = self.classifier(features)\n",
    "                cls_loss = self.cross_entropy(probs, torch.flatten(reals))\n",
    "                # de_cls_loss = self.cross_entropy(probs, torch.ones([embs.shape[0]], dtype=torch.long).to(self.device))\n",
    "                # de_cls_loss = torch.reciprocal(self.cross_entropy(probs, torch.flatten(reals)) + self.eps)\n",
    "                de_cls_loss = self.cross_entropy(probs, torch.flatten(1 - reals))\n",
    "\n",
    "                # Decoder reconstruct\n",
    "                recons = self.decoder(features)\n",
    "                \n",
    "                # ListNet Loss\n",
    "                de_loss = de_loss_weight * MythNet(recons, labels) + cls_loss_weight * de_cls_loss\n",
    "                de_val_loss += de_loss.item()\n",
    "                cls_val_loss += cls_loss.item()\n",
    "                \n",
    "                # Precision for reconstruct\n",
    "                precision_scores = retrieval_precision_all(recons, labels, k=self.config['topk'])\n",
    "                for k, v in precision_scores.items():\n",
    "                    results['[Recon] Precision v1@{}'.format(k)].append(v)\n",
    "                \n",
    "                precision_scores = retrieval_precision_all_v2(recons, labels, k=self.config['topk'])\n",
    "                for k, v in precision_scores.items():\n",
    "                    results['[Recon] Precision v2@{}'.format(k)].append(v)\n",
    "\n",
    "                # NDCG for reconstruct\n",
    "                ndcg_scores = retrieval_normalized_dcg_all(recons, labels, k=self.config['topk'])\n",
    "                for k, v in ndcg_scores.items():\n",
    "                    results['[Recon] ndcg@{}'.format(k)].append(v)\n",
    "        \n",
    "        avg_de_val_loss = de_val_loss / len(loader)\n",
    "        avg_cls_val_loss = cls_val_loss / len(loader)\n",
    "        \n",
    "        for k in results:\n",
    "            results[k] = np.mean(results[k])\n",
    "                \n",
    "        return avg_de_val_loss, results, avg_cls_val_loss\n",
    "    \n",
    "    def de_fit(self):\n",
    "        self.decoder.to(self.device)\n",
    "        self.extractor.to(self.device)\n",
    "        self.classifier.to(self.device)\n",
    "\n",
    "        fake_weight = [len(self.label_set)] * len(self.unlabel_set)\n",
    "        real_weight = [len(self.unlabel_set)] * len(self.label_set)\n",
    "\n",
    "        sampler = WeightedRandomSampler(fake_weight+real_weight, len(self.merge_set), replacement=True)\n",
    "\n",
    "        train_loader = DataLoader(self.merge_set, batch_size=self.config['batch_size'], shuffle=False, num_workers=self.num_data_loader_workers, sampler=sampler)\n",
    "        valid_loader = DataLoader(self.valid_set, batch_size=self.config['batch_size'], shuffle=False, num_workers=self.num_data_loader_workers)\n",
    "        \n",
    "        for epoch in range(self.config['de_epochs']):\n",
    "            de_train_loss = self.de_training(epoch, train_loader)\n",
    "            cls_train_loss = self.cls_training(epoch, train_loader)\n",
    "\n",
    "            print('---------------------------------------')\n",
    "            print(\"Training: \")\n",
    "            print(\" [Decoder] Average training loss: {0:.3f}\".format(de_train_loss))\n",
    "            print(\" [Classifier] Average training loss: {0:.3f}\".format(cls_train_loss))\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                de_val_loss, de_val_res, cls_val_loss = self.de_validation(valid_loader)\n",
    "            \n",
    "                print(\"Validation:\")\n",
    "                print(\" [Decoder] Average validation loss: {0:.3f}\".format(de_val_loss))\n",
    "                print(\" [Classifier] Average validation loss: {0:.3f}\".format(cls_val_loss))\n",
    "                print(\" [Decoder] Average validation result:\")\n",
    "\n",
    "                for key,val in de_val_res.items():\n",
    "                    print(f\"{key}:{val:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a7beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'experiment': 'autoencoder_testting',\n",
    "    'model': 'VAE',\n",
    "    'architecture': 'concatenate',\n",
    "    'activation': 'sigmoid',\n",
    "    'dataset': '20news',\n",
    "    'vocab_size':0,\n",
    "    'encoder': 'mpnet',\n",
    "    'target': 'tf-idf-gensim',\n",
    "    'seed': 123,\n",
    "    'epochs': 20,\n",
    "    'de_epochs': 20,\n",
    "    'en_epochs':0,\n",
    "    'lr': 1e-4,\n",
    "    'ae_lr':1e-4,\n",
    "    'optim': 'AdamW',\n",
    "    'scheduler': False,\n",
    "    'warmup': 'linear',\n",
    "    'warmup_proportion': 0.1, \n",
    "    'loss': 'listnet',\n",
    "    'batch_size': 32,\n",
    "    'weight_decay': 0,\n",
    "    'ratio': 0.1,\n",
    "    'topk': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "    'save': False,\n",
    "    'threshold': 0.7,\n",
    "    'balance': False,\n",
    "}\n",
    "same_seeds(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cde68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "if config['dataset'] == '20news':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 62, 1.0, 15\n",
    "elif config['dataset'] == 'agnews':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 425, 1.0, 15\n",
    "elif config['dataset'] == 'IMDB':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 166, 1.0, 15\n",
    "elif config['dataset'] == 'wiki':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 2872, 1.0, 15\n",
    "elif config['dataset'] == 'tweet':\n",
    "    config['min_df'], config['max_df'], config['min_doc_word'] = 5, 1.0, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924603b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting preprocess documents: 20news\n",
      "min_df: 62 max_df: 1.0 vocabulary_size: None min_doc_word: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/casimir0304/miniconda3/envs/ide/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Load corpus done.\n",
      "Getting preprocess documents embeddings\n",
      "Using cuda 0 for training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd123600bc94dfbaa818ed8cbd2cd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generate embedding done.\n",
      "Getting preprocess documents labels\n",
      "[INFO] Load label done.\n",
      "[INFO] Generate id2token done.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "unpreprocessed_corpus ,preprocessed_corpus = get_preprocess_document(**config)\n",
    "texts = [text.split() for text in preprocessed_corpus]\n",
    "print('[INFO] Load corpus done.')\n",
    "\n",
    "# Generating document embedding\n",
    "while True:\n",
    "    try:\n",
    "        doc_embs, doc_model, device = get_preprocess_document_embs(preprocessed_corpus, config['encoder'])\n",
    "        break\n",
    "    except:\n",
    "        print('[Error] CUDA Memory Insufficient, retry after 15 secondes.')\n",
    "        time.sleep(15)\n",
    "print('[INFO] Generate embedding done.')\n",
    "\n",
    "# Generate Decode target & Vocabulary\n",
    "if config['target'] == 'keybert' or config['target'] == 'yake':\n",
    "    labels, vocabularys= load_preprocess_document_labels(config)\n",
    "    label = labels[config['target']].toarray()\n",
    "else:\n",
    "    labels, vocabularys= get_preprocess_document_labels(preprocessed_corpus)\n",
    "    label = labels[config['target']]\n",
    "    vocabularys = vocabularys[config['target']]\n",
    "print('[INFO] Load label done.')\n",
    "\n",
    "# generate idx to token\n",
    "id2token = {k: v for k, v in zip(range(0, len(vocabularys)), vocabularys)}\n",
    "print('[INFO] Generate id2token done.')\n",
    "\n",
    "reals = np.ones((doc_embs.shape[0], 1))\n",
    "\n",
    "dataset = IDEDataset(unpreprocessed_corpus, preprocessed_corpus, doc_embs, label, reals)\n",
    "label_length = int(len(dataset) * config['ratio'])\n",
    "unlabel_length = int(len(dataset) * (0.8 - config['ratio']))\n",
    "validation_length = len(dataset) - label_length - unlabel_length\n",
    "label_set, unlabel_set, validation_set = random_split(dataset, lengths=[label_length, unlabel_length, validation_length], generator=torch.Generator().manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de9578ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = IDEDADecoder(config, label_set, unlabel_set, validation_set, vocabularys, id2token, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff7638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Encoder Training...\n",
      "---------------------------------------\n",
      "Training: \n",
      " [Encoder] Average training loss: 28.778\n",
      " [Encoder] Average training distance: 10.829\n",
      " [Encoder] Average training cosine similarity: 0.429\n",
      "Validation:\n",
      " [Encoder] Average validation loss: 26.473\n",
      " [Encoder] Average validation dis: 10.463\n",
      " [Encoder] Average validation cosine similarity: 0.499\n"
     ]
    }
   ],
   "source": [
    "model.en_fit()\n",
    "model.de_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b767e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ft = torch.nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7b12c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(32, 768)\n",
    "output = torch.rand(32, 768)\n",
    "target = torch.ones(input.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "51a21a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input.unsqueeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9e0b1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv1d(768, 1024, 1, stride=2)\n",
    "n = nn.Conv1d(1024, 2048, 1, stride=2)\n",
    "p = nn.Linear(2048, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4de86f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0ce9006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "60781a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ii = n(f_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fdce82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ii = f_ii.squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5903023b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2048])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1b4a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_i = p(f_ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f0eb354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7780],\n",
       "        [0.7515],\n",
       "        [0.0189],\n",
       "        [0.2546],\n",
       "        [0.2149],\n",
       "        [0.0862],\n",
       "        [0.5484],\n",
       "        [0.2309],\n",
       "        [0.4746],\n",
       "        [0.7762],\n",
       "        [0.1945],\n",
       "        [0.3249],\n",
       "        [0.9649],\n",
       "        [0.2566],\n",
       "        [0.2249],\n",
       "        [0.1953],\n",
       "        [0.8901],\n",
       "        [0.9546],\n",
       "        [0.4946],\n",
       "        [0.6430],\n",
       "        [0.8602],\n",
       "        [0.3492],\n",
       "        [0.5560],\n",
       "        [0.8231],\n",
       "        [0.2780],\n",
       "        [0.1194],\n",
       "        [0.9353],\n",
       "        [0.0206],\n",
       "        [0.6764],\n",
       "        [0.5586],\n",
       "        [0.4602],\n",
       "        [0.7814],\n",
       "        [0.8910],\n",
       "        [0.0398],\n",
       "        [0.4550],\n",
       "        [0.1149],\n",
       "        [0.3009],\n",
       "        [0.4356],\n",
       "        [0.4032],\n",
       "        [0.0020],\n",
       "        [0.4546],\n",
       "        [0.7572],\n",
       "        [0.8089],\n",
       "        [0.0862],\n",
       "        [0.3820],\n",
       "        [0.0703],\n",
       "        [0.7150],\n",
       "        [0.5383],\n",
       "        [0.5395],\n",
       "        [0.9188],\n",
       "        [0.5681],\n",
       "        [0.5385],\n",
       "        [0.5496],\n",
       "        [0.9235],\n",
       "        [0.2063],\n",
       "        [0.3648],\n",
       "        [0.2066],\n",
       "        [0.9905],\n",
       "        [0.9344],\n",
       "        [0.4977],\n",
       "        [0.6972],\n",
       "        [0.4779],\n",
       "        [0.3822],\n",
       "        [0.0192],\n",
       "        [0.5446],\n",
       "        [0.2101],\n",
       "        [0.9274],\n",
       "        [0.8748],\n",
       "        [0.4406],\n",
       "        [0.6247],\n",
       "        [0.6961],\n",
       "        [0.9322],\n",
       "        [0.0189],\n",
       "        [0.5747],\n",
       "        [0.2055],\n",
       "        [0.6807],\n",
       "        [0.8085],\n",
       "        [0.6494],\n",
       "        [0.4355],\n",
       "        [0.2836],\n",
       "        [0.5387],\n",
       "        [0.0521],\n",
       "        [0.5917],\n",
       "        [0.6720],\n",
       "        [0.2828],\n",
       "        [0.0857],\n",
       "        [0.8741],\n",
       "        [0.9971],\n",
       "        [0.1067],\n",
       "        [0.8015],\n",
       "        [0.9590],\n",
       "        [0.2104],\n",
       "        [0.3927],\n",
       "        [0.4325],\n",
       "        [0.6967],\n",
       "        [0.4189],\n",
       "        [0.2348],\n",
       "        [0.5230],\n",
       "        [0.7591],\n",
       "        [0.4192],\n",
       "        [0.7468],\n",
       "        [0.7565],\n",
       "        [0.0829],\n",
       "        [0.2017],\n",
       "        [0.5010],\n",
       "        [0.7845],\n",
       "        [0.5885],\n",
       "        [0.5202],\n",
       "        [0.2919],\n",
       "        [0.7220],\n",
       "        [0.1335],\n",
       "        [0.2628],\n",
       "        [0.7151],\n",
       "        [0.5251],\n",
       "        [0.8551],\n",
       "        [0.4175],\n",
       "        [0.2292],\n",
       "        [0.1032],\n",
       "        [0.8100],\n",
       "        [0.6260],\n",
       "        [0.2309],\n",
       "        [0.2868],\n",
       "        [0.1503],\n",
       "        [0.1487],\n",
       "        [0.4089],\n",
       "        [0.6416],\n",
       "        [0.1538],\n",
       "        [0.5211],\n",
       "        [0.2199],\n",
       "        [0.4985],\n",
       "        [0.3458],\n",
       "        [0.0546],\n",
       "        [0.9782],\n",
       "        [0.5882],\n",
       "        [0.6547],\n",
       "        [0.7218],\n",
       "        [0.2469],\n",
       "        [0.3547],\n",
       "        [0.7311],\n",
       "        [0.6360],\n",
       "        [0.6708],\n",
       "        [0.7550],\n",
       "        [0.0070],\n",
       "        [0.6391],\n",
       "        [0.8488],\n",
       "        [0.9220],\n",
       "        [0.7691],\n",
       "        [0.3415],\n",
       "        [0.7247],\n",
       "        [0.0820],\n",
       "        [0.3453],\n",
       "        [0.2884],\n",
       "        [0.0111],\n",
       "        [0.9992],\n",
       "        [0.5335],\n",
       "        [0.9384],\n",
       "        [0.0675],\n",
       "        [0.7412],\n",
       "        [0.0534],\n",
       "        [0.0021],\n",
       "        [0.9589],\n",
       "        [0.2772],\n",
       "        [0.3112],\n",
       "        [0.9290],\n",
       "        [0.3959],\n",
       "        [0.4843],\n",
       "        [0.3093],\n",
       "        [0.9982],\n",
       "        [0.5777],\n",
       "        [0.1945],\n",
       "        [0.3573],\n",
       "        [0.7167],\n",
       "        [0.8397],\n",
       "        [0.5013],\n",
       "        [0.2397],\n",
       "        [0.8505],\n",
       "        [0.6817],\n",
       "        [0.5725],\n",
       "        [0.6820],\n",
       "        [0.9806],\n",
       "        [0.3471],\n",
       "        [0.9657],\n",
       "        [0.7102],\n",
       "        [0.6075],\n",
       "        [0.9478],\n",
       "        [0.7074],\n",
       "        [0.8806],\n",
       "        [0.3280],\n",
       "        [0.2912],\n",
       "        [0.4148],\n",
       "        [0.1421],\n",
       "        [0.1572],\n",
       "        [0.1323],\n",
       "        [0.5689],\n",
       "        [0.7335],\n",
       "        [0.6510],\n",
       "        [0.7476],\n",
       "        [0.4646],\n",
       "        [0.6214],\n",
       "        [0.3759],\n",
       "        [0.4528],\n",
       "        [0.6311],\n",
       "        [0.7634],\n",
       "        [0.8492],\n",
       "        [0.4436],\n",
       "        [0.8821],\n",
       "        [0.9399],\n",
       "        [0.9489],\n",
       "        [0.9524],\n",
       "        [0.8471],\n",
       "        [0.2281],\n",
       "        [0.8275],\n",
       "        [0.7529],\n",
       "        [0.3968],\n",
       "        [0.0129],\n",
       "        [0.3929],\n",
       "        [0.6319],\n",
       "        [0.2795],\n",
       "        [0.4844],\n",
       "        [0.4307],\n",
       "        [0.6618],\n",
       "        [0.0816],\n",
       "        [0.8466],\n",
       "        [0.1847],\n",
       "        [0.9846],\n",
       "        [0.0020],\n",
       "        [0.5235],\n",
       "        [0.1974],\n",
       "        [0.6081],\n",
       "        [0.8887],\n",
       "        [0.2639],\n",
       "        [0.2348],\n",
       "        [0.5210],\n",
       "        [0.2503],\n",
       "        [0.3035],\n",
       "        [0.7914],\n",
       "        [0.6085],\n",
       "        [0.7154],\n",
       "        [0.9438],\n",
       "        [0.0730],\n",
       "        [0.9736],\n",
       "        [0.5378],\n",
       "        [0.1761],\n",
       "        [0.8361],\n",
       "        [0.0218],\n",
       "        [0.5595],\n",
       "        [0.9322],\n",
       "        [0.9713],\n",
       "        [0.0299],\n",
       "        [0.6219],\n",
       "        [0.5294],\n",
       "        [0.6027],\n",
       "        [0.0191],\n",
       "        [0.5572],\n",
       "        [0.4228],\n",
       "        [0.2284],\n",
       "        [0.3719],\n",
       "        [0.8018],\n",
       "        [0.9844],\n",
       "        [0.4753],\n",
       "        [0.4762],\n",
       "        [0.0930],\n",
       "        [0.1245],\n",
       "        [0.4144],\n",
       "        [0.3636],\n",
       "        [0.0021],\n",
       "        [0.9977],\n",
       "        [0.7258],\n",
       "        [0.2628],\n",
       "        [0.0986],\n",
       "        [0.7527],\n",
       "        [0.9713],\n",
       "        [0.7649],\n",
       "        [0.7262],\n",
       "        [0.0268],\n",
       "        [0.3507],\n",
       "        [0.8708],\n",
       "        [0.6493],\n",
       "        [0.7141],\n",
       "        [0.6583],\n",
       "        [0.6034],\n",
       "        [0.5990],\n",
       "        [0.3451],\n",
       "        [0.7907],\n",
       "        [0.7018],\n",
       "        [0.3166],\n",
       "        [0.7101],\n",
       "        [0.2663],\n",
       "        [0.2177],\n",
       "        [0.3832],\n",
       "        [0.9024],\n",
       "        [0.5369],\n",
       "        [0.9235],\n",
       "        [0.0271],\n",
       "        [0.2714],\n",
       "        [0.4989],\n",
       "        [0.1278],\n",
       "        [0.9402],\n",
       "        [0.5472],\n",
       "        [0.5762],\n",
       "        [0.6124],\n",
       "        [0.8897],\n",
       "        [0.7552],\n",
       "        [0.9121],\n",
       "        [0.3083],\n",
       "        [0.0650],\n",
       "        [0.9816],\n",
       "        [0.3994],\n",
       "        [0.0033],\n",
       "        [0.7667],\n",
       "        [0.2598],\n",
       "        [0.6750],\n",
       "        [0.3263],\n",
       "        [0.0383],\n",
       "        [0.5518],\n",
       "        [0.6031],\n",
       "        [0.0021],\n",
       "        [0.2971],\n",
       "        [0.2974],\n",
       "        [0.5334],\n",
       "        [0.7041],\n",
       "        [0.6396],\n",
       "        [0.0036],\n",
       "        [0.4831],\n",
       "        [0.8087],\n",
       "        [0.5600],\n",
       "        [0.1390],\n",
       "        [0.1432],\n",
       "        [0.3465],\n",
       "        [0.7966],\n",
       "        [0.8136],\n",
       "        [0.6569],\n",
       "        [0.1902],\n",
       "        [0.5026],\n",
       "        [0.8231],\n",
       "        [0.2322],\n",
       "        [0.8242],\n",
       "        [0.0612],\n",
       "        [0.3681],\n",
       "        [0.3965],\n",
       "        [0.7910],\n",
       "        [0.7618],\n",
       "        [0.1369],\n",
       "        [0.9899],\n",
       "        [0.0660],\n",
       "        [0.2505],\n",
       "        [0.4354],\n",
       "        [0.0414],\n",
       "        [0.9095],\n",
       "        [0.3977],\n",
       "        [0.6138],\n",
       "        [0.4781],\n",
       "        [0.7250],\n",
       "        [0.2949],\n",
       "        [0.4167],\n",
       "        [0.8187],\n",
       "        [0.7471],\n",
       "        [0.9996],\n",
       "        [0.4204],\n",
       "        [0.8288],\n",
       "        [0.0896],\n",
       "        [0.2786],\n",
       "        [0.5144],\n",
       "        [0.2329],\n",
       "        [0.7594],\n",
       "        [0.5746],\n",
       "        [0.4328],\n",
       "        [0.1512],\n",
       "        [0.3211],\n",
       "        [0.4356],\n",
       "        [0.2857],\n",
       "        [0.5294],\n",
       "        [0.2694],\n",
       "        [0.0794],\n",
       "        [0.0942],\n",
       "        [0.4001],\n",
       "        [0.3442],\n",
       "        [0.1388],\n",
       "        [0.4239],\n",
       "        [0.1975],\n",
       "        [0.6352],\n",
       "        [0.5930],\n",
       "        [0.8647],\n",
       "        [0.4031],\n",
       "        [0.5966],\n",
       "        [0.2338],\n",
       "        [0.6360],\n",
       "        [0.2690],\n",
       "        [0.5097],\n",
       "        [0.6464],\n",
       "        [0.4171],\n",
       "        [0.6180],\n",
       "        [0.2478],\n",
       "        [0.6194],\n",
       "        [0.8296],\n",
       "        [0.4304],\n",
       "        [0.4173],\n",
       "        [0.2370],\n",
       "        [0.7679],\n",
       "        [0.7475],\n",
       "        [0.1539],\n",
       "        [0.3068],\n",
       "        [0.3806],\n",
       "        [0.3549],\n",
       "        [0.9957],\n",
       "        [0.5519],\n",
       "        [0.4881],\n",
       "        [0.4187],\n",
       "        [0.9364],\n",
       "        [0.4566],\n",
       "        [0.3877],\n",
       "        [0.5056],\n",
       "        [0.2451],\n",
       "        [0.0043],\n",
       "        [0.0757],\n",
       "        [0.8664],\n",
       "        [0.8562],\n",
       "        [0.0817],\n",
       "        [0.0126],\n",
       "        [0.2977],\n",
       "        [0.1415],\n",
       "        [0.2499],\n",
       "        [0.4306],\n",
       "        [0.1728],\n",
       "        [0.5763],\n",
       "        [0.8992],\n",
       "        [0.5427],\n",
       "        [0.2996],\n",
       "        [0.1608],\n",
       "        [0.5850],\n",
       "        [0.7539],\n",
       "        [0.2902],\n",
       "        [0.4149],\n",
       "        [0.8397],\n",
       "        [0.8332],\n",
       "        [0.2609],\n",
       "        [0.5780],\n",
       "        [0.3902],\n",
       "        [0.6743],\n",
       "        [0.7467],\n",
       "        [0.8859],\n",
       "        [0.9793],\n",
       "        [0.6058],\n",
       "        [0.5578],\n",
       "        [0.6213],\n",
       "        [0.7827],\n",
       "        [0.1851],\n",
       "        [0.1611],\n",
       "        [0.6694],\n",
       "        [0.6960],\n",
       "        [0.5120],\n",
       "        [0.4609],\n",
       "        [0.7485],\n",
       "        [0.8116],\n",
       "        [0.4835],\n",
       "        [0.9605],\n",
       "        [0.4121],\n",
       "        [0.2649],\n",
       "        [0.3914],\n",
       "        [0.7240],\n",
       "        [0.8357],\n",
       "        [0.6388],\n",
       "        [0.2373],\n",
       "        [0.7816],\n",
       "        [0.3092],\n",
       "        [0.5954],\n",
       "        [0.1687],\n",
       "        [0.3811],\n",
       "        [0.2057],\n",
       "        [0.1563],\n",
       "        [0.1927],\n",
       "        [0.4374],\n",
       "        [0.8080],\n",
       "        [0.8551],\n",
       "        [0.1724],\n",
       "        [0.7327],\n",
       "        [0.7438],\n",
       "        [0.7009],\n",
       "        [0.1071],\n",
       "        [0.7297],\n",
       "        [0.6899],\n",
       "        [0.2603],\n",
       "        [0.6717],\n",
       "        [0.6743],\n",
       "        [0.3115],\n",
       "        [0.7556],\n",
       "        [0.1130],\n",
       "        [0.6130],\n",
       "        [0.9125],\n",
       "        [0.5425],\n",
       "        [0.3677],\n",
       "        [0.7867],\n",
       "        [0.3948],\n",
       "        [0.1202],\n",
       "        [0.6849],\n",
       "        [0.5743],\n",
       "        [0.6573],\n",
       "        [0.8888],\n",
       "        [0.1498],\n",
       "        [0.1498],\n",
       "        [0.6836],\n",
       "        [0.9484],\n",
       "        [0.8845],\n",
       "        [0.1235],\n",
       "        [0.6260],\n",
       "        [0.3410],\n",
       "        [0.3438],\n",
       "        [0.0478],\n",
       "        [0.1193],\n",
       "        [0.8641],\n",
       "        [0.1821],\n",
       "        [0.4170],\n",
       "        [0.4471],\n",
       "        [0.4465],\n",
       "        [0.1220],\n",
       "        [0.1167],\n",
       "        [0.5509],\n",
       "        [0.1137],\n",
       "        [0.3329],\n",
       "        [0.4006],\n",
       "        [0.5899],\n",
       "        [0.3061],\n",
       "        [0.3828],\n",
       "        [0.2009],\n",
       "        [0.6882],\n",
       "        [0.0648],\n",
       "        [0.1190],\n",
       "        [0.9405],\n",
       "        [0.1723],\n",
       "        [0.3281],\n",
       "        [0.4080],\n",
       "        [0.0688],\n",
       "        [0.2386],\n",
       "        [0.5584],\n",
       "        [0.3452],\n",
       "        [0.5056],\n",
       "        [0.2582],\n",
       "        [0.9216],\n",
       "        [0.4567],\n",
       "        [0.7531],\n",
       "        [0.6344],\n",
       "        [0.7612],\n",
       "        [0.8790],\n",
       "        [0.7533],\n",
       "        [0.6549],\n",
       "        [0.9989],\n",
       "        [0.3330],\n",
       "        [0.0381],\n",
       "        [0.5499],\n",
       "        [0.3139],\n",
       "        [0.2321],\n",
       "        [0.4325],\n",
       "        [0.0154],\n",
       "        [0.3781],\n",
       "        [0.0807],\n",
       "        [0.2486],\n",
       "        [0.8955],\n",
       "        [0.2944],\n",
       "        [0.0524],\n",
       "        [0.5279],\n",
       "        [0.1192],\n",
       "        [0.9989],\n",
       "        [0.7332],\n",
       "        [0.1475],\n",
       "        [0.4288],\n",
       "        [0.1721],\n",
       "        [0.6265],\n",
       "        [0.6914],\n",
       "        [0.2553],\n",
       "        [0.6747],\n",
       "        [0.9076],\n",
       "        [0.8045],\n",
       "        [0.0436],\n",
       "        [0.2232],\n",
       "        [0.4230],\n",
       "        [0.2363],\n",
       "        [0.3423],\n",
       "        [0.1619],\n",
       "        [0.4140],\n",
       "        [0.6262],\n",
       "        [0.7322],\n",
       "        [0.6510],\n",
       "        [0.7060],\n",
       "        [0.1629],\n",
       "        [0.9248],\n",
       "        [0.3902],\n",
       "        [0.1751],\n",
       "        [0.6479],\n",
       "        [0.7428],\n",
       "        [0.7310],\n",
       "        [0.0716],\n",
       "        [0.8351],\n",
       "        [0.4371],\n",
       "        [0.7167],\n",
       "        [0.1586],\n",
       "        [0.6775],\n",
       "        [0.2368],\n",
       "        [0.6118],\n",
       "        [0.9874],\n",
       "        [0.5884],\n",
       "        [0.9481],\n",
       "        [0.0318],\n",
       "        [0.4290],\n",
       "        [0.8412],\n",
       "        [0.5350],\n",
       "        [0.3723],\n",
       "        [0.2534],\n",
       "        [0.0535],\n",
       "        [0.7559],\n",
       "        [0.5240],\n",
       "        [0.2527],\n",
       "        [0.2638],\n",
       "        [0.6364],\n",
       "        [0.0276],\n",
       "        [0.4048],\n",
       "        [0.8610],\n",
       "        [0.5064],\n",
       "        [0.1555],\n",
       "        [0.2602],\n",
       "        [0.9223],\n",
       "        [0.2922],\n",
       "        [0.3338],\n",
       "        [0.6932],\n",
       "        [0.2244],\n",
       "        [0.1260],\n",
       "        [0.6692],\n",
       "        [0.4820],\n",
       "        [0.1295],\n",
       "        [0.7990],\n",
       "        [0.2271],\n",
       "        [0.1925],\n",
       "        [0.6685],\n",
       "        [0.0810],\n",
       "        [0.8604],\n",
       "        [0.9676],\n",
       "        [0.5818],\n",
       "        [0.5363],\n",
       "        [0.0504],\n",
       "        [0.3397],\n",
       "        [0.9988],\n",
       "        [0.4926],\n",
       "        [0.3987],\n",
       "        [0.7985],\n",
       "        [0.4818],\n",
       "        [0.3935],\n",
       "        [0.0599],\n",
       "        [0.8000],\n",
       "        [0.6778],\n",
       "        [0.3078],\n",
       "        [0.6522],\n",
       "        [0.0134],\n",
       "        [0.3357],\n",
       "        [0.5038],\n",
       "        [0.3486],\n",
       "        [0.9117],\n",
       "        [0.9148],\n",
       "        [0.7610],\n",
       "        [0.6043],\n",
       "        [0.5171],\n",
       "        [0.9609],\n",
       "        [0.7689],\n",
       "        [0.4124],\n",
       "        [0.9357],\n",
       "        [0.5223],\n",
       "        [0.8133],\n",
       "        [0.9936],\n",
       "        [0.2838],\n",
       "        [0.7603],\n",
       "        [0.7146],\n",
       "        [0.9796],\n",
       "        [0.6215],\n",
       "        [0.7128],\n",
       "        [0.7029],\n",
       "        [0.8064],\n",
       "        [0.1666],\n",
       "        [0.6417],\n",
       "        [0.7415],\n",
       "        [0.2969],\n",
       "        [0.1464],\n",
       "        [0.1451],\n",
       "        [0.9178],\n",
       "        [0.1078],\n",
       "        [0.4794],\n",
       "        [0.8555],\n",
       "        [0.5888],\n",
       "        [0.4046],\n",
       "        [0.5546],\n",
       "        [0.7273],\n",
       "        [0.4169],\n",
       "        [0.4518],\n",
       "        [0.7964],\n",
       "        [0.5687],\n",
       "        [0.6582],\n",
       "        [0.7918],\n",
       "        [0.0711],\n",
       "        [0.7276],\n",
       "        [0.6891],\n",
       "        [0.6234],\n",
       "        [0.3875],\n",
       "        [0.8429],\n",
       "        [0.9375],\n",
       "        [0.0236],\n",
       "        [0.6910],\n",
       "        [0.9273],\n",
       "        [0.8169],\n",
       "        [0.8049],\n",
       "        [0.3387],\n",
       "        [0.5847],\n",
       "        [0.7532],\n",
       "        [0.8900],\n",
       "        [0.2365],\n",
       "        [0.0960],\n",
       "        [0.5929],\n",
       "        [0.8132],\n",
       "        [0.6864],\n",
       "        [0.8406],\n",
       "        [0.2442],\n",
       "        [0.3557],\n",
       "        [0.5351],\n",
       "        [0.9106],\n",
       "        [0.5857],\n",
       "        [0.7485],\n",
       "        [0.1027],\n",
       "        [0.8424],\n",
       "        [0.4614],\n",
       "        [0.5447],\n",
       "        [0.8731],\n",
       "        [0.3846],\n",
       "        [0.8701],\n",
       "        [0.8259],\n",
       "        [0.0028],\n",
       "        [0.4588],\n",
       "        [0.9600],\n",
       "        [0.3887],\n",
       "        [0.5983],\n",
       "        [0.5366],\n",
       "        [0.4290],\n",
       "        [0.3342],\n",
       "        [0.5066],\n",
       "        [0.3537],\n",
       "        [0.9283],\n",
       "        [0.4229],\n",
       "        [0.7850],\n",
       "        [0.6774],\n",
       "        [0.7821],\n",
       "        [0.7767],\n",
       "        [0.5742],\n",
       "        [0.6186],\n",
       "        [0.6789],\n",
       "        [0.5225],\n",
       "        [0.9381],\n",
       "        [0.7384],\n",
       "        [0.2638],\n",
       "        [0.4239],\n",
       "        [0.0979],\n",
       "        [0.6789],\n",
       "        [0.7965],\n",
       "        [0.1502],\n",
       "        [0.5322],\n",
       "        [0.8905],\n",
       "        [0.2055],\n",
       "        [0.4740],\n",
       "        [0.7614],\n",
       "        [0.6590],\n",
       "        [0.3091],\n",
       "        [0.2465],\n",
       "        [0.7349],\n",
       "        [0.1701]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2955394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5675],\n",
       "        [-0.0274],\n",
       "        [ 0.3374],\n",
       "        ...,\n",
       "        [ 0.1751],\n",
       "        [-0.2532],\n",
       "        [-0.3159]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb145a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5675],\n",
       "        [-0.0274],\n",
       "        [ 0.3374],\n",
       "        ...,\n",
       "        [ 0.1751],\n",
       "        [-0.2532],\n",
       "        [-0.3159]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b80fb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, hidden_dim=1024):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, 1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim*2, 1, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, feature_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, embs):\n",
    "        conv_embs = self.cnn(embs.unsqueeze(dim=-1))\n",
    "        feature = self.fc(conv_embs.squeeze(dim=-1))\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd339f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([32, 768])\n",
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "model = FeatureExtractor(768, 768)\n",
    "train_loader = DataLoader(label_set, batch_size=config['batch_size'], shuffle=False)\n",
    "for batch, (docs, corpus, embs, labels) in enumerate(train_loader):\n",
    "    features = model(embs)\n",
    "    print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9c6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = torch.rand([32, 768])\n",
    "fake = torch.rand([32, 768])\n",
    "margin = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27e4261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance = F.pairwise_distance(real, fake, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3118ff72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b95a7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance = torch.cdist(fake, real, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5098c171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41554784",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.eye(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d6164d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_contrastive = torch.mean((1-label) * torch.pow(dist, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(margin - dist, min=0.0), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7a9480f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b391630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(123.8685)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a7df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ce = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daca114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand([32, 2])\n",
    "soft = torch.nn.Softmax(dim=-1)\n",
    "soft_input = soft(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d93946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_ce(soft_input, torch.ones([input.shape[0]], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ef7622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6956)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "702da045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones([input.shape[0]], dtype=torch.long).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a0e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs1 = torch.rand([32, 768])\n",
    "embs2 = torch.rand([32, 768])\n",
    "embs3 = torch.rand([32, 768])\n",
    "embs4 = torch.rand([32, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cde8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs5 = torch.stack((embs1, embs2, embs3), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c3e486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8183250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn = nn.MultiheadAttention(768, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2b8a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, weight = multihead_attn(embs3, embs2, embs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82c0ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = nn.Transformer(d_model=768, nhead=16, num_encoder_layers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6e0be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = transformer_model(embs1, embs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbd969fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6732, -0.1739,  0.7569,  ...,  0.3597,  2.2979, -0.2133],\n",
       "        [-0.0127, -0.1261, -0.1806,  ...,  0.1698,  3.0161, -0.1863],\n",
       "        [ 0.5780, -0.2042,  0.3258,  ...,  0.7780,  1.7690, -0.0397],\n",
       "        ...,\n",
       "        [-0.9630, -0.9636,  0.8446,  ...,  0.2313,  1.2824, -0.5504],\n",
       "        [-0.8126, -0.2329,  0.5636,  ...,  0.0285,  2.2121,  0.1297],\n",
       "        [-0.1163, -0.2724,  0.5043,  ...,  0.6184,  1.7682, -0.0203]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d658014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4434938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embs1.unsqueeze(dim=-1)\n",
    "y = embs2.unsqueeze(dim=-1)\n",
    "z = embs3.unsqueeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a36bb6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 768, but got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output, weight \u001b[38;5;241m=\u001b[39m \u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/casimir0304/miniconda3/envs/ide/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data1/casimir0304/miniconda3/envs/ide/lib/python3.9/site-packages/torch/nn/modules/activation.py:1153\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m   1142\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1143\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         q_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight, k_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1151\u001b[0m         v_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj_weight, average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights)\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1153\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/data1/casimir0304/miniconda3/envs/ide/lib/python3.9/site-packages/torch/nn/functional.py:5046\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[1;32m   5044\u001b[0m tgt_len, bsz, embed_dim \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   5045\u001b[0m src_len, _, _ \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m-> 5046\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m embed_dim \u001b[38;5;241m==\u001b[39m embed_dim_to_check, \\\n\u001b[1;32m   5047\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas expecting embedding dimension of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embed_dim, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m   5049\u001b[0m     \u001b[38;5;66;03m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[1;32m   5050\u001b[0m     head_dim \u001b[38;5;241m=\u001b[39m embed_dim\u001b[38;5;241m.\u001b[39mdiv(num_heads, rounding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrunc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: was expecting embedding dimension of 768, but got 1"
     ]
    }
   ],
   "source": [
    "output, weight = multihead_attn(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7391326",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Sequential(\n",
    "        nn.Conv2d(768, 1024, 2, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(1024, 1024*2, 2, stride=2),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "fc= nn.Sequential(\n",
    "        nn.Linear(1024*2, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(1024, 768),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b47078e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 3, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs5.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a123cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv2d(1, 3, (3, 1), stride=1)\n",
    "n = nn.Conv2d(3, 6, 2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb00875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = m(embs5.unsqueeze(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "262743bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 1, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b04605a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1 x 384). Kernel size: (2 x 2). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/casimir0304/miniconda3/envs/ide/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data1/casimir0304/miniconda3/envs/ide/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/casimir0304/miniconda3/envs/ide/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1 x 384). Kernel size: (2 x 2). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "g = n(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af661262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
